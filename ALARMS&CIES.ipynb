{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>signal</th>\n",
       "      <th>threshold</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "      <th>(Q28) New Critical Illness Event During hospitalization (CIE)</th>\n",
       "      <th>(Q29) Number of critical Illness events during hospitalization (CIE)</th>\n",
       "      <th>Events_Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:06:26</td>\n",
       "      <td>2022-07-12 10:06:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:06:34</td>\n",
       "      <td>2022-07-12 10:06:52</td>\n",
       "      <td>18.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:06:55</td>\n",
       "      <td>2022-07-12 10:06:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:07:05</td>\n",
       "      <td>2022-07-12 10:09:30</td>\n",
       "      <td>145.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>SPO2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2022-07-12 10:07:18</td>\n",
       "      <td>2022-07-12 10:12:30</td>\n",
       "      <td>312.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741837</th>\n",
       "      <td>Z-H-0387</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-07-02 12:00:53</td>\n",
       "      <td>2023-07-02 12:01:12</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741838</th>\n",
       "      <td>Z-H-0387</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-07-02 12:01:55</td>\n",
       "      <td>2023-07-02 12:02:02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741839</th>\n",
       "      <td>Z-H-0387</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-07-02 12:02:46</td>\n",
       "      <td>2023-07-02 12:02:53</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741840</th>\n",
       "      <td>Z-H-0387</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-07-02 12:03:24</td>\n",
       "      <td>2023-07-02 12:03:31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741841</th>\n",
       "      <td>Z-H-0387</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-07-02 12:04:49</td>\n",
       "      <td>2023-07-02 12:04:59</td>\n",
       "      <td>10.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2741842 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id signal  threshold           start_time  \\\n",
       "0         B-N-0001  ECGRR       50.0  2022-07-12 10:06:26   \n",
       "1         B-N-0001  ECGRR       50.0  2022-07-12 10:06:34   \n",
       "2         B-N-0001  ECGRR       50.0  2022-07-12 10:06:55   \n",
       "3         B-N-0001  ECGRR       50.0  2022-07-12 10:07:05   \n",
       "4         B-N-0001   SPO2       90.0  2022-07-12 10:07:18   \n",
       "...            ...    ...        ...                  ...   \n",
       "2741837   Z-H-0387  ECGRR       40.0  2023-07-02 12:00:53   \n",
       "2741838   Z-H-0387  ECGRR       40.0  2023-07-02 12:01:55   \n",
       "2741839   Z-H-0387  ECGRR       40.0  2023-07-02 12:02:46   \n",
       "2741840   Z-H-0387  ECGRR       40.0  2023-07-02 12:03:24   \n",
       "2741841   Z-H-0387  ECGRR       40.0  2023-07-02 12:04:49   \n",
       "\n",
       "                    end_time  duration  value  count  \\\n",
       "0        2022-07-12 10:06:27       1.0   69.0    2.0   \n",
       "1        2022-07-12 10:06:52      18.0   77.0   19.0   \n",
       "2        2022-07-12 10:06:56       1.0   56.0    2.0   \n",
       "3        2022-07-12 10:09:30     145.0   53.0  145.0   \n",
       "4        2022-07-12 10:12:30     312.0   84.0  310.0   \n",
       "...                      ...       ...    ...    ...   \n",
       "2741837  2023-07-02 12:01:12      19.0   41.0   21.0   \n",
       "2741838  2023-07-02 12:02:02       7.0   43.0    8.0   \n",
       "2741839  2023-07-02 12:02:53       7.0   44.0    8.0   \n",
       "2741840  2023-07-02 12:03:31       7.0   43.0    8.0   \n",
       "2741841  2023-07-02 12:04:59      10.0   43.0   11.0   \n",
       "\n",
       "        (Q28) New Critical Illness Event During hospitalization (CIE)  \\\n",
       "0                                                      NaN              \n",
       "1                                                      NaN              \n",
       "2                                                      NaN              \n",
       "3                                                      NaN              \n",
       "4                                                      NaN              \n",
       "...                                                    ...              \n",
       "2741837                                                NaN              \n",
       "2741838                                                NaN              \n",
       "2741839                                                NaN              \n",
       "2741840                                                NaN              \n",
       "2741841                                                NaN              \n",
       "\n",
       "         (Q29) Number of critical Illness events during hospitalization (CIE)  \\\n",
       "0                                                      NaN                      \n",
       "1                                                      NaN                      \n",
       "2                                                      NaN                      \n",
       "3                                                      NaN                      \n",
       "4                                                      NaN                      \n",
       "...                                                    ...                      \n",
       "2741837                                                NaN                      \n",
       "2741838                                                NaN                      \n",
       "2741839                                                NaN                      \n",
       "2741840                                                NaN                      \n",
       "2741841                                                NaN                      \n",
       "\n",
       "        Events_Column  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "2741837           NaN  \n",
       "2741838           NaN  \n",
       "2741839           NaN  \n",
       "2741840           NaN  \n",
       "2741841           NaN  \n",
       "\n",
       "[2741842 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "csv_file=r\"C:/Users/user/Music/IMPALA3/file.csv\"\n",
    "df=pd.read_csv(csv_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Age_months</th>\n",
       "      <th>Sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>HR_threshold</th>\n",
       "      <th>SpO2_threshold</th>\n",
       "      <th>RR_threshold</th>\n",
       "      <th>HR2_threshold</th>\n",
       "      <th>SpO22_threshold</th>\n",
       "      <th>RR2_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-N-0002</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-N-0003</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-N-0004</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>Female</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-N-0006</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Female</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Z-H-0347</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 5-12 Years</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Z-H-0365</td>\n",
       "      <td>36.799999</td>\n",
       "      <td>Female</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Z-H-0368</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Z-H-0376</td>\n",
       "      <td>32.400002</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Z-H-0386</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  Age_months     Sex          age_group  HR_threshold  \\\n",
       "0     B-N-0001    3.100000    Male  PED - 1-11 Months           180   \n",
       "1     B-N-0002    3.400000    Male  PED - 1-11 Months           180   \n",
       "2     B-N-0003    2.400000    Male  PED - 1-11 Months           180   \n",
       "3     B-N-0004    4.700000  Female  PED - 1-11 Months           180   \n",
       "4     B-N-0006    2.000000  Female  PED - 1-11 Months           180   \n",
       "..         ...         ...     ...                ...           ...   \n",
       "360   Z-H-0347   52.000000    Male   PED - 5-12 Years           130   \n",
       "361   Z-H-0365   36.799999  Female    PED - 1-4 Years           150   \n",
       "362   Z-H-0368   44.700001    Male    PED - 1-4 Years           150   \n",
       "363   Z-H-0376   32.400002    Male    PED - 1-4 Years           150   \n",
       "364   Z-H-0386   46.799999    Male    PED - 1-4 Years           150   \n",
       "\n",
       "     SpO2_threshold  RR_threshold  HR2_threshold  SpO22_threshold  \\\n",
       "0                90            50            200              100   \n",
       "1                90            50            200              100   \n",
       "2                90            50            200              100   \n",
       "3                90            50            200              100   \n",
       "4                90            50            200              100   \n",
       "..              ...           ...            ...              ...   \n",
       "360              90            30            170              100   \n",
       "361              90            40            190              100   \n",
       "362              90            40            190              100   \n",
       "363              90            40            190              100   \n",
       "364              90            40            190              100   \n",
       "\n",
       "     RR2_threshold  \n",
       "0               70  \n",
       "1               70  \n",
       "2               70  \n",
       "3               70  \n",
       "4               70  \n",
       "..             ...  \n",
       "360             50  \n",
       "361             60  \n",
       "362             60  \n",
       "363             60  \n",
       "364             60  \n",
       "\n",
       "[365 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Stata file into a DataFrame\n",
    "df2 = pd.read_stata('IMPALAage.dta')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Distribution:\n",
      "Sex\n",
      "Male      203\n",
      "Female    162\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing patient data\n",
    "# Let's assume 'Sex' is the column containing sex information\n",
    "\n",
    "# Count the number of male and female patients\n",
    "sex_distribution = df2['Sex'].value_counts()\n",
    "\n",
    "# Print the demographic distribution\n",
    "print(\"Demographic Distribution:\")\n",
    "print(sex_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.2 GiB for an array with shape (6, 407634724) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming df and df2 are your DataFrames\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatient_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malldataage.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:848\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[0;32m    842\u001b[0m )\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m--> 848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m     left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(lmgr, axes\u001b[38;5;241m=\u001b[39mlmgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    858\u001b[0m left\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 18.2 GiB for an array with shape (6, 407634724) and data type object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df and df2 are your DataFrames\n",
    "merged_df = pd.merge(df, df, on='patient_id', how='inner')\n",
    "merged_df.to_csv('alldataage.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events_Column\n",
      "Respiratory support            69\n",
      "Convulsion                     51\n",
      "Blood transfusion              46\n",
      "Sepsis                         42\n",
      "Death                          36\n",
      "Intravenous fluid bolus        17\n",
      "Coma                           14\n",
      "ICU                            11\n",
      "bronchodilator support         10\n",
      "Respiratory Support            10\n",
      "IV or enteral                   5\n",
      "Malaria treatment               5\n",
      "Transfusion of blood            4\n",
      "Inotropic support               3\n",
      "Respiratory                     3\n",
      "Respiratory support+D14:E39     1\n",
      "death                           1\n",
      " Blood transfusion              1\n",
      "surgical procedure              1\n",
      "Name: count, dtype: int64\n",
      "Events_Column\n",
      "Respiratory support            0.209091\n",
      "Convulsion                     0.154545\n",
      "Blood transfusion              0.139394\n",
      "Sepsis                         0.127273\n",
      "Death                          0.109091\n",
      "Intravenous fluid bolus        0.051515\n",
      "Coma                           0.042424\n",
      "ICU                            0.033333\n",
      "bronchodilator support         0.030303\n",
      "Respiratory Support            0.030303\n",
      "IV or enteral                  0.015152\n",
      "Malaria treatment              0.015152\n",
      "Transfusion of blood           0.012121\n",
      "Inotropic support              0.009091\n",
      "Respiratory                    0.009091\n",
      "Respiratory support+D14:E39    0.003030\n",
      "death                          0.003030\n",
      " Blood transfusion             0.003030\n",
      "surgical procedure             0.003030\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df['Events_Column'].value_counts()\n",
    "print(summary_stats)\n",
    "proportions = df['Events_Column'].value_counts(normalize=True)\n",
    "print(proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Counts for Alarms with Duration\n",
      "+----------+---------+\n",
      "| Signal   |   Count |\n",
      "|----------+---------|\n",
      "| SPO2     |  201670 |\n",
      "| ECGRR    | 1772439 |\n",
      "| ECGHR    |  537069 |\n",
      "+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define a list of signals you want to count\n",
    "signals_to_count = ['SPO2', 'ECGRR', 'ECGHR']\n",
    "\n",
    "# Create an empty dictionary to store signal counts\n",
    "signal_counts = {}\n",
    "\n",
    "# Iterate over the list of signals\n",
    "for signal in signals_to_count:\n",
    "    # Count occurrences of the signal in the filtered alarms\n",
    "    signal_count = df[df['signal'] == signal].shape[0]\n",
    "    signal_counts[signal] = signal_count\n",
    "\n",
    "# Print the signal counts\n",
    "print(\"Signal Counts for Alarms with Duration\")\n",
    "print(tabulate.tabulate(signal_counts.items(), headers=['Signal', 'Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 772\n"
     ]
    }
   ],
   "source": [
    "num_patients = df['patient_id'].nunique()\n",
    "print(\"Number of patients:\", num_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% PATIENT WITHOUT CRITICAL ILLNESS EVENTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patient_id  signal  threshold           start_time  \\\n",
      "711       B-N-0002   ECGHR      180.0  2022-07-13 10:07:47   \n",
      "712       B-N-0002   ECGRR       50.0  2022-07-13 10:07:47   \n",
      "713       B-N-0002   ECGRR       50.0  2022-07-13 10:08:49   \n",
      "714       B-N-0002    SPO2       90.0  2022-07-13 10:09:06   \n",
      "715       B-N-0002  SPO2HR      180.0  2022-07-13 10:09:06   \n",
      "...            ...     ...        ...                  ...   \n",
      "2725402   Z-H-0382   ECGRR       40.0  2023-06-26 20:47:11   \n",
      "2725403   Z-H-0382   ECGRR       40.0  2023-06-26 20:47:56   \n",
      "2725404   Z-H-0382   ECGRR       40.0  2023-06-26 20:50:05   \n",
      "2725405   Z-H-0382   ECGRR       40.0  2023-06-26 20:50:33   \n",
      "2725406   Z-H-0382   ECGRR       40.0  2023-06-26 20:51:56   \n",
      "\n",
      "                    end_time  duration  value  count  \\\n",
      "711      2022-07-13 10:23:52     965.0  198.0  949.0   \n",
      "712      2022-07-13 10:08:41      54.0   66.0   49.0   \n",
      "713      2022-07-13 10:09:09      20.0   52.0   21.0   \n",
      "714      2022-07-13 10:12:17     191.0   82.0   35.0   \n",
      "715      2022-07-13 10:12:17     191.0  190.0   31.0   \n",
      "...                      ...       ...    ...    ...   \n",
      "2725402  2023-06-26 20:47:12       1.0   41.0    2.0   \n",
      "2725403  2023-06-26 20:48:30      34.0   45.0   35.0   \n",
      "2725404  2023-06-26 20:50:14       9.0   44.0   10.0   \n",
      "2725405  2023-06-26 20:50:47      14.0   41.0   15.0   \n",
      "2725406  2023-06-26 20:52:17      21.0   41.0   22.0   \n",
      "\n",
      "        (Q28) New Critical Illness Event During hospitalization (CIE)  \\\n",
      "711                                                    NaN              \n",
      "712                                                    NaN              \n",
      "713                                                    NaN              \n",
      "714                                                    NaN              \n",
      "715                                                    NaN              \n",
      "...                                                    ...              \n",
      "2725402                                                NaN              \n",
      "2725403                                                NaN              \n",
      "2725404                                                NaN              \n",
      "2725405                                                NaN              \n",
      "2725406                                                NaN              \n",
      "\n",
      "         (Q29) Number of critical Illness events during hospitalization (CIE)  \\\n",
      "711                                                    NaN                      \n",
      "712                                                    NaN                      \n",
      "713                                                    NaN                      \n",
      "714                                                    NaN                      \n",
      "715                                                    NaN                      \n",
      "...                                                    ...                      \n",
      "2725402                                                NaN                      \n",
      "2725403                                                NaN                      \n",
      "2725404                                                NaN                      \n",
      "2725405                                                NaN                      \n",
      "2725406                                                NaN                      \n",
      "\n",
      "        Events_Column  \n",
      "711               NaN  \n",
      "712               NaN  \n",
      "713               NaN  \n",
      "714               NaN  \n",
      "715               NaN  \n",
      "...               ...  \n",
      "2725402           NaN  \n",
      "2725403           NaN  \n",
      "2725404           NaN  \n",
      "2725405           NaN  \n",
      "2725406           NaN  \n",
      "\n",
      "[1537483 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provided list of patient IDs\n",
    "patient_ids = [\n",
    "    'B-N-0001', 'B-N-0003', 'B-N-0006','B-N-0007', 'B-N-0009', 'B-N-0017', 'B-N-0021', 'B-N-0025',  'B-N-0029',  'B-N-0038',\n",
    "    'B-N-0039', 'B-N-0041', 'B-N-0048', 'B-N-0050', 'B-N-0054', 'B-N-0057', 'B-N-0058', 'B-N-0059','B-N-0066', 'B-N-0072', 'B-N-0073', 'B-N-0074', 'B-N-0075', 'B-N-0076', 'B-N-0081','B-N-0083', 'B-N-0084', 'B-N-0085', 'B-N-0086', 'B-N-0088', 'B-N-0089', 'B-N-0091', 'B-S-0005', \n",
    "    'B-S-0013', 'B-S-0014', 'B-S-0017', 'B-S-0022','B-S-0027', 'B-S-0034', 'B-S-0039',\n",
    "    'B-S-0060', 'B-S-0064', 'B-S-0073', 'B-S-0074', 'B-S-0075', 'B-S-0076', 'B-S-0082', 'B-S-0084',\n",
    "    'B-S-0086', 'B-S-0090', 'B-S-0093', 'B-S-0096', 'B-S-0097', 'B-S-0102',\n",
    "    'B-S-0104', 'B-S-0110',  'B-S-0111', 'B-S-0117', 'B-S-0122', 'B-S-0125', 'B-S-0137', 'B-S-0148',\n",
    "    'B-S-0150', 'B-S-0154', 'B-S-0155', 'B-S-0167', 'B-S-0168', 'B-S-0169', 'B-S-0183', 'B-S-0192', 'B-S-0193',\n",
    "    'B-S-0209', 'B-S-0213', 'B-S-0222', 'B-S-0223', 'B-S-0228', 'B-S-0235', 'B-S-0239', 'B-S-0242', 'B-S-0250', 'B-S-0252', 'B-S-0259',\n",
    "    'B-S-0267', 'B-S-0269', 'B-S-0270', 'B-S-0271', 'B-S-0276', 'B-S-0277', 'B-S-0278', 'B-S-0282',  'B-S-0283', 'B-S-0283', 'B-S-0284',\n",
    "    'B-S-0292', 'B-S-0299', 'Z-H-0001', 'Z-H-0002', 'Z-H-0003', 'Z-H-0004',  'Z-H-0007', 'Z-H-0008', 'Z-H-0009', 'Z-H-0010', 'Z-H-0018', \n",
    "    'Z-H-0022', 'Z-H-0024', 'Z-H-0025', 'Z-H-0029', 'Z-H-0030', 'Z-H-0032','Z-H-0032',  'Z-H-0033', 'Z-H-0035', 'Z-H-0036', 'Z-H-0043', 'Z-H-0046', 'Z-H-0047',\n",
    "    'Z-H-0052', 'Z-H-0053', 'Z-H-0054',  'Z-H-0058', 'Z-H-0062', 'Z-H-0064', 'Z-H-0067', 'Z-H-0074', 'Z-H-0078', 'Z-H-0080',  'Z-H-0083', 'Z-H-0084', \n",
    "    'Z-H-0089', 'Z-H-0092', 'Z-H-0094', 'Z-H-0098',  'Z-H-0103', 'Z-H-0108', 'Z-H-0108', 'Z-H-0109',\n",
    "    'Z-H-0112', 'Z-H-0114', 'Z-H-0114',   'Z-H-0116', 'Z-H-0120','Z-H-0120',  'Z-H-0122', 'Z-H-0122', 'Z-H-0123', 'Z-H-0124', 'Z-H-0124', 'Z-H-0126',\n",
    "    'Z-H-0130',  'Z-H-0131', 'Z-H-0135', 'Z-H-0137',  'Z-H-0141','Z-H-0144', 'Z-H-0146', 'Z-H-0149', 'Z-H-0154', 'Z-H-0157','Z-H-0161',  'Z-H-0162', 'Z-H-0165', 'Z-H-0166', 'Z-H-0179', 'Z-H-0180',\n",
    "    'Z-H-0180',  'Z-H-0183', 'Z-H-0185',  'Z-H-0188', 'Z-H-0189','Z-H-0193', 'Z-H-0196', 'Z-H-0198', 'Z-H-0200', 'Z-H-0204', 'Z-H-0208',\n",
    "    'Z-H-0210',  'Z-H-0216', 'Z-H-0222', 'Z-H-0223', 'Z-H-0225', 'Z-H-0226', 'Z-H-0226', 'Z-H-0228','Z-H-0231', 'Z-H-0233', 'Z-H-0238', 'Z-H-0242', 'Z-H-0243', 'Z-H-0243', 'Z-H-0244', 'Z-H-0245', 'Z-H-0245',\n",
    "    'Z-H-0249',  'Z-H-0250', 'Z-H-0258', 'Z-H-0261', 'Z-H-0262', 'Z-H-0264',\n",
    "    'Z-H-0265', 'Z-H-0268', 'Z-H-0269',  'Z-H-0270','Z-H-0272', 'Z-H-0275', 'Z-H-0276', 'Z-H-0280', 'Z-H-0283', 'Z-H-0292',  'Z-H-0296',\n",
    "    'Z-H-0300', 'Z-H-0301', 'Z-H-0302', 'Z-H-0304', 'Z-H-0306', 'Z-H-0308', 'Z-H-0310',\n",
    "    'Z-H-0312', 'Z-H-0316', 'Z-H-0317', 'Z-H-0318',  'Z-H-0320', 'Z-H-0320',\n",
    "    'Z-H-0320', 'Z-H-0321',  'Z-H-0323', 'Z-H-0324', 'Z-H-0332', 'Z-H-0333', \n",
    "    'Z-H-0335', 'Z-H-0336', 'Z-H-0338', 'Z-H-0339',  'Z-H-0341', 'Z-H-0344', 'Z-H-0346', \n",
    "    'Z-H-0348', 'Z-H-0350', 'Z-H-0352', 'Z-H-0357',  'Z-H-0358', 'Z-H-0362', 'Z-H-0363',\n",
    "    'Z-H-0364', 'Z-H-0365', 'Z-H-0366', 'Z-H-0367', 'Z-H-0374', 'Z-H-0383',  'Z-H-0384',\n",
    "    'Z-H-0385', 'Z-H-0386', 'Z-H-0387'\n",
    "]\n",
    "# Filter out rows with patient IDs shared with the provided list\n",
    "filtered_data = df[~df['patient_id'].isin(patient_ids)]\n",
    "\n",
    "# Now, filtered_data contains only the data of patients not present in the provided list\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patient_id signal  threshold           start_time  \\\n",
      "714       B-N-0002   SPO2       90.0  2022-07-13 10:09:06   \n",
      "722       B-N-0002   SPO2       90.0  2022-07-13 10:18:20   \n",
      "837       B-N-0002   SPO2       90.0  2022-07-14 05:58:24   \n",
      "863       B-N-0002   SPO2       90.0  2022-07-14 06:14:02   \n",
      "865       B-N-0002   SPO2       90.0  2022-07-14 06:14:31   \n",
      "...            ...    ...        ...                  ...   \n",
      "1214273   B-S-0310   SPO2       90.0  2023-06-19 01:16:12   \n",
      "1214275   B-S-0310   SPO2       90.0  2023-06-19 01:21:27   \n",
      "1214381   B-S-0310   SPO2       90.0  2023-06-19 07:10:05   \n",
      "1215262   B-S-0311   SPO2       90.0  2023-06-21 10:45:44   \n",
      "1216023   B-S-0312   SPO2       90.0  2023-06-23 08:17:54   \n",
      "\n",
      "                    end_time  duration  value  count  \\\n",
      "714      2022-07-13 10:12:17     191.0   82.0   35.0   \n",
      "722      2022-07-14 05:19:12   68452.0   80.0  127.0   \n",
      "837      2022-07-14 06:13:06     882.0   84.0   86.0   \n",
      "863      2022-07-14 06:14:03       1.0   70.0    2.0   \n",
      "865      2022-07-14 06:14:33       2.0   70.0    3.0   \n",
      "...                      ...       ...    ...    ...   \n",
      "1214273  2023-06-19 01:16:21       9.0   60.0   10.0   \n",
      "1214275  2023-06-19 01:21:50      23.0   82.0    9.0   \n",
      "1214381  2023-06-19 07:10:06       1.0   84.0    2.0   \n",
      "1215262  2023-06-21 10:48:13     149.0   66.0   17.0   \n",
      "1216023  2023-06-23 08:18:42      48.0   84.0   48.0   \n",
      "\n",
      "        (Q28) New Critical Illness Event During hospitalization (CIE)  \\\n",
      "714                                                    NaN              \n",
      "722                                                    NaN              \n",
      "837                                                    NaN              \n",
      "863                                                    NaN              \n",
      "865                                                    NaN              \n",
      "...                                                    ...              \n",
      "1214273                                                NaN              \n",
      "1214275                                                NaN              \n",
      "1214381                                                NaN              \n",
      "1215262                                                NaN              \n",
      "1216023                                                NaN              \n",
      "\n",
      "         (Q29) Number of critical Illness events during hospitalization (CIE)  \\\n",
      "714                                                    NaN                      \n",
      "722                                                    NaN                      \n",
      "837                                                    NaN                      \n",
      "863                                                    NaN                      \n",
      "865                                                    NaN                      \n",
      "...                                                    ...                      \n",
      "1214273                                                NaN                      \n",
      "1214275                                                NaN                      \n",
      "1214381                                                NaN                      \n",
      "1215262                                                NaN                      \n",
      "1216023                                                NaN                      \n",
      "\n",
      "        Events_Column  \n",
      "714               NaN  \n",
      "722               NaN  \n",
      "837               NaN  \n",
      "863               NaN  \n",
      "865               NaN  \n",
      "...               ...  \n",
      "1214273           NaN  \n",
      "1214275           NaN  \n",
      "1214381           NaN  \n",
      "1215262           NaN  \n",
      "1216023           NaN  \n",
      "\n",
      "[6075 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Filter the DataFrame based on conditions\n",
    "filtered_df = filtered_data[((filtered_data['patient_id'].str.startswith('B-N')) | (filtered_data['patient_id'].str.startswith('B-S'))) & \n",
    "                 ((filtered_data['signal'] == 'ECGHR') & (filtered_data['value'] > 200) & (filtered_data['value'] <50) |\n",
    "                  (filtered_data['signal'] == 'ECGRR') & (filtered_data['value'] > 70) & (filtered_data['value'] < 15) |\n",
    "                  (filtered_data['signal'] == 'SPO2') & (filtered_data['value'] < 85))]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 532\n"
     ]
    }
   ],
   "source": [
    "num_patients = filtered_data['patient_id'].nunique()\n",
    "print(\"Number of patients:\", num_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% Delay Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Counts for Alarms with Duration\n",
      "+----------+---------+\n",
      "| Signal   |   Count |\n",
      "|----------+---------|\n",
      "| SPO2     |  110885 |\n",
      "| ECGRR    |  994413 |\n",
      "| ECGHR    |  310853 |\n",
      "+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define a list of signals you want to count\n",
    "signals_to_count = ['SPO2', 'ECGRR', 'ECGHR']\n",
    "\n",
    "# Create an empty dictionary to store signal counts\n",
    "signal_counts = {}\n",
    "\n",
    "# Iterate over the list of signals\n",
    "for signal in signals_to_count:\n",
    "    # Count occurrences of the signal in the filtered alarms\n",
    "    signal_count = filtered_data[filtered_data['signal'] == signal].shape[0]\n",
    "    signal_counts[signal] = signal_count\n",
    "\n",
    "# Print the signal counts\n",
    "print(\"Signal Counts for Alarms with Duration\")\n",
    "print(tabulate.tabulate(signal_counts.items(), headers=['Signal', 'Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15364\\3886602789.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['duration_bin'] = pd.cut(filtered_data['duration'], bins=duration_bins, labels=duration_labels, right=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15364\\3886602789.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  signal_duration_counts = filtered_data.groupby(['signal', 'duration_bin']).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Counts at Different Duration Ranges:\n",
      "duration_bin   < 10s  10-15s  15-20s  20-30s  30-45s  45-60s  >= 60s\n",
      "signal                                                              \n",
      "ECGHR         188064   29008   21596   21034   15558    8364   27229\n",
      "ECGRR         408721  181093   98198  109140   75388   37130   84743\n",
      "SPO2           40534   10363    8175    9707    8425    5184   28497\n",
      "SPO2HR         59370   11466    7875    9449    7703    4599   20870\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create bins for different duration ranges\n",
    "duration_bins = [0, 10, 15, 20, 30, 45, 60, float('inf')]\n",
    "duration_labels = ['< 10s', '10-15s', '15-20s', '20-30s', '30-45s', '45-60s', '>= 60s']\n",
    "\n",
    "# Categorize the duration into bins\n",
    "filtered_data['duration_bin'] = pd.cut(filtered_data['duration'], bins=duration_bins, labels=duration_labels, right=False)\n",
    "\n",
    "# Group by signal and duration bin, then count occurrences\n",
    "signal_duration_counts = filtered_data.groupby(['signal', 'duration_bin']).size().unstack(fill_value=0)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Signal Counts at Different Duration Ranges:\")\n",
    "print(signal_duration_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%%Calculation of alarm per hour(mean,medium,std.minimum and maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15364\\4158984811.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15364\\4158984811.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.hour\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15364\\4158984811.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['duration_bin'] = pd.cut(filtered_data['duration'], bins=duration_bins, labels=duration_labels, right=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15364\\4158984811.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  hourly_signal_duration_counts = filtered_data.groupby(['hour', 'signal', 'duration_bin']).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Statistics:\n",
      "duration_bin  < 10s                                            10-15s  \\\n",
      "                sum     mean  median          std   min    max    sum   \n",
      "hour                                                                    \n",
      "0             23201  5800.25  4339.0  5234.173693  1660  12863   7483   \n",
      "1             23301  5825.25  4155.0  5512.365153  1520  13471   7487   \n",
      "2             23879  5969.75  4256.0  5621.837444  1601  13766   7574   \n",
      "3             27138  6784.50  4714.0  6392.716559  1919  15791   7967   \n",
      "4             28359  7089.75  4623.5  7207.337667  1862  17250   8581   \n",
      "5             28233  7058.25  5225.5  6764.013718  1586  16196   9146   \n",
      "6             31434  7858.50  5352.5  7893.899860  1800  18929  10595   \n",
      "7             33743  8435.75  5910.5  8431.097057  1728  20194  11281   \n",
      "8             33580  8395.00  5518.0  8876.258822  1609  20935  11886   \n",
      "9             35153  8788.25  6253.5  8847.695420  1633  21013  11629   \n",
      "10            32639  8159.75  5655.0  8245.526843  1629  19700  11220   \n",
      "11            32114  8028.50  5706.5  8059.137940  1543  19158  10771   \n",
      "12            30168  7542.00  5538.5  7186.631803  1746  17345  10190   \n",
      "13            28664  7166.00  5156.5  7022.538715  1539  16812   9754   \n",
      "14            30333  7583.25  5721.0  7106.135442  1720  17171  10321   \n",
      "15            29334  7333.50  5452.5  7059.300839  1535  16894   9983   \n",
      "16            29790  7447.50  5261.5  7332.001750  1657  17610  10319   \n",
      "17            30963  7740.75  5622.5  7548.171053  1558  18160  10562   \n",
      "18            31062  7765.50  5536.5  7603.333501  1687  18302  10610   \n",
      "19            30037  7509.25  5301.5  7443.169055  1641  17793  10160   \n",
      "20            29128  7282.00  5399.0  6745.352326  1860  16470   9699   \n",
      "21            25937  6484.25  4592.0  6166.912322  1662  15091   8633   \n",
      "22            24148  6037.00  4295.0  5753.958521  1496  14062   8137   \n",
      "23            24351  6087.75  4454.5  5629.721330  1697  13745   7942   \n",
      "\n",
      "duration_bin                                ... 45-60s                         \\\n",
      "                 mean  median          std  ... median         std  min   max   \n",
      "hour                                        ...                                 \n",
      "0             1870.75   686.5  2606.801920  ...  257.0  524.079113  141  1256   \n",
      "1             1871.75   661.5  2609.981657  ...  245.0  562.520814  150  1334   \n",
      "2             1893.50   618.0  2737.843616  ...  231.0  600.260152  130  1393   \n",
      "3             1991.75   669.0  2870.387358  ...  232.5  579.275985   87  1332   \n",
      "4             2145.25   770.5  3027.932890  ...  258.5  645.979618  152  1509   \n",
      "5             2286.50   821.0  3229.489691  ...  258.5  680.144592  176  1583   \n",
      "6             2648.75   853.5  3854.228879  ...  319.0  699.982143  199  1669   \n",
      "7             2820.25   956.0  4103.824426  ...  326.5  744.420748  227  1775   \n",
      "8             2971.50   972.5  4368.895703  ...  304.0  756.942699  212  1781   \n",
      "9             2907.25   961.5  4245.430750  ...  305.0  770.919094  194  1801   \n",
      "10            2805.00   949.0  4066.585136  ...  289.0  741.873305  210  1740   \n",
      "11            2692.75   910.5  3904.251732  ...  281.0  746.062777  211  1745   \n",
      "12            2547.50   967.0  3519.099553  ...  292.5  613.574975  211  1483   \n",
      "13            2438.50   855.5  3463.501359  ...  302.0  622.649380  215  1508   \n",
      "14            2580.25   909.0  3662.754735  ...  303.5  660.557530  214  1588   \n",
      "15            2495.75   935.5  3498.549259  ...  300.0  654.426976  199  1565   \n",
      "16            2579.75   903.5  3697.731951  ...  328.5  675.867529  200  1626   \n",
      "17            2640.50   970.5  3741.768254  ...  330.0  675.826654  203  1627   \n",
      "18            2652.50  1002.0  3689.125777  ...  323.5  664.710714  239  1616   \n",
      "19            2540.00   893.5  3625.159031  ...  285.5  687.384111  200  1624   \n",
      "20            2424.75   900.0  3320.382144  ...  287.5  644.197175  200  1541   \n",
      "21            2158.25   734.5  3064.763653  ...  269.0  597.394551  196  1435   \n",
      "22            2034.25   725.5  2855.313920  ...  259.0  555.917860  147  1327   \n",
      "23            1985.50   744.5  2758.935604  ...  259.5  530.497487  139  1271   \n",
      "\n",
      "duration_bin >= 60s                                            \n",
      "                sum     mean  median          std   min   max  \n",
      "hour                                                           \n",
      "0              5988  1497.00  1021.0  1239.796220   612  3334  \n",
      "1              5988  1497.00   957.0  1303.149007   637  3437  \n",
      "2              6044  1511.00  1013.5  1336.385423   531  3486  \n",
      "3              5914  1478.50   970.0  1364.395959   479  3495  \n",
      "4              6145  1536.25  1030.0  1326.606039   584  3501  \n",
      "5              6624  1656.00  1066.5  1385.600472   768  3723  \n",
      "6              7163  1790.75  1245.0  1311.635715   928  3745  \n",
      "7              7450  1862.50  1306.5  1339.313879   979  3858  \n",
      "8              7358  1839.50  1299.0  1255.377101  1046  3714  \n",
      "9              7128  1782.00  1281.0  1220.623338   967  3599  \n",
      "10             6938  1734.50  1264.5  1173.394648   934  3475  \n",
      "11             6800  1700.00  1261.0  1090.953711   957  3321  \n",
      "12             6675  1668.75  1199.5  1085.776335   986  3290  \n",
      "13             6544  1636.00  1158.0  1085.676747   971  3257  \n",
      "14             6946  1736.50  1252.5  1109.238327  1047  3394  \n",
      "15             6824  1706.00  1153.5  1208.217696  1002  3515  \n",
      "16             6981  1745.25  1271.0  1074.762416  1087  3352  \n",
      "17             7101  1775.25  1253.0  1145.992547  1104  3491  \n",
      "18             7426  1856.50  1236.5  1325.702958  1110  3843  \n",
      "19             7082  1770.50  1146.0  1368.622300   972  3818  \n",
      "20             6995  1748.75  1192.0  1295.000997   930  3681  \n",
      "21             6514  1628.50  1152.5  1189.866799   813  3396  \n",
      "22             6370  1592.50  1061.5  1287.119394   738  3509  \n",
      "23             6341  1585.25  1071.5  1296.575329   688  3510  \n",
      "\n",
      "[24 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert start_time to datetime\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "\n",
    "# Extract hour from start_time\n",
    "filtered_data['hour'] = filtered_data['start_time'].dt.hour\n",
    "\n",
    "# Create bins for different duration ranges\n",
    "duration_bins = [0, 10, 15, 20, 30, 45, 60, float('inf')]\n",
    "duration_labels = ['< 10s', '10-15s', '15-20s', '20-30s', '30-45s', '45-60s', '>= 60s']\n",
    "\n",
    "# Categorize the duration into bins\n",
    "filtered_data['duration_bin'] = pd.cut(filtered_data['duration'], bins=duration_bins, labels=duration_labels, right=False)\n",
    "\n",
    "# Group by hour, signal, and duration bin, then count occurrences\n",
    "hourly_signal_duration_counts = filtered_data.groupby(['hour', 'signal', 'duration_bin']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate statistics per hour\n",
    "hourly_statistics = hourly_signal_duration_counts.groupby(level=0).agg(['sum', 'mean', 'median', 'std', 'min', 'max'])\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Hourly Statistics:\")\n",
    "print(hourly_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4628\\2845206466.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4628\\2845206466.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4628\\2845206466.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Statistics:\n",
      "count    7692.000000\n",
      "mean      199.880785\n",
      "std       139.898841\n",
      "min         1.000000\n",
      "25%        94.000000\n",
      "50%       175.000000\n",
      "75%       278.000000\n",
      "max      2746.000000\n",
      "dtype: float64\n",
      "\n",
      "Number of Patients per Hour:\n",
      "hour\n",
      "2022-07-08 01:00:00    1\n",
      "2022-07-08 02:00:00    1\n",
      "2022-07-08 03:00:00    1\n",
      "2022-07-08 04:00:00    1\n",
      "2022-07-08 05:00:00    1\n",
      "                      ..\n",
      "2023-06-28 08:00:00    2\n",
      "2023-06-28 09:00:00    1\n",
      "2023-06-28 10:00:00    2\n",
      "2023-06-28 11:00:00    2\n",
      "2023-06-28 12:00:00    2\n",
      "Name: patient_id, Length: 7692, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert start_time to datetime\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "\n",
    "# Round start_time to the nearest hour to create hourly windows\n",
    "filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
    "\n",
    "# Group by hour and count occurrences\n",
    "hourly_counts = filtered_data.groupby('hour').size()\n",
    "\n",
    "# Count the number of unique patient IDs per hour\n",
    "patients_per_hour = filtered_data.groupby('hour')['patient_id'].nunique()\n",
    "\n",
    "# Calculate statistics per hour\n",
    "hourly_statistics = hourly_counts.describe()\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Hourly Statistics:\")\n",
    "print(hourly_statistics)\n",
    "\n",
    "# Print the number of patients per hour\n",
    "print(\"\\nNumber of Patients per Hour:\")\n",
    "print(patients_per_hour)\n",
    "patients_per_hour.to_excel(\"patient_per_hour.xlsx\", header=[\"Alarm Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6584\\1424263339.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6584\\1424263339.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6584\\1424263339.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Statistics:\n",
      "count    7692.000000\n",
      "mean      199.880785\n",
      "std       139.898841\n",
      "min         1.000000\n",
      "25%        94.000000\n",
      "50%       175.000000\n",
      "75%       278.000000\n",
      "max      2746.000000\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Alarm Counts for Each Hour:\n",
      "hour\n",
      "2022-07-08 01:00:00     37\n",
      "2022-07-08 02:00:00     61\n",
      "2022-07-08 03:00:00     21\n",
      "2022-07-08 04:00:00     95\n",
      "2022-07-08 05:00:00    190\n",
      "                      ... \n",
      "2023-06-28 08:00:00    162\n",
      "2023-06-28 09:00:00    141\n",
      "2023-06-28 10:00:00    181\n",
      "2023-06-28 11:00:00     75\n",
      "2023-06-28 12:00:00     66\n",
      "Name: value, Length: 7692, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert start_time to datetime\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "\n",
    "# Round start_time to the nearest hour to create hourly windows\n",
    "filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
    "\n",
    "# Group by hour and count the values (number of alarms)\n",
    "hourly_counts = filtered_data.groupby('hour')['value'].count()\n",
    "\n",
    "# Calculate statistics per hour\n",
    "hourly_statistics = hourly_counts.describe()\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Hourly Statistics:\")\n",
    "print(hourly_statistics)\n",
    "\n",
    "# Print alarm counts for each hour\n",
    "print(\"\\nAlarm Counts for Each Hour:\")\n",
    "print(hourly_counts)\n",
    "\n",
    "# Save alarm counts for each hour to an Excel file\n",
    "hourly_counts.to_excel(\"hourly_alarm_counts.xlsx\", header=[\"Alarm Count\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarms per Patient:\n",
      "patient_id\n",
      "B-N-0002    1215\n",
      "B-N-0004    2192\n",
      "B-N-0008    4781\n",
      "B-N-0010    1402\n",
      "B-N-0011     602\n",
      "            ... \n",
      "Z-H-0378    2186\n",
      "Z-H-0379    3908\n",
      "Z-H-0380    6267\n",
      "Z-H-0381    6385\n",
      "Z-H-0382    1130\n",
      "Name: value, Length: 532, dtype: int64\n",
      "\n",
      "Statistics for Alarms per Patient:\n",
      "count      532.000000\n",
      "mean      2890.005639\n",
      "std       2788.638436\n",
      "min          1.000000\n",
      "25%       1082.000000\n",
      "50%       2019.500000\n",
      "75%       3765.000000\n",
      "max      19179.000000\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'filtered_data' DataFrame is defined and 'start_time' column is converted to datetime\n",
    "\n",
    "# Group by patient_id and count the values\n",
    "alarms_per_patient = filtered_data.groupby('patient_id')['value'].count()\n",
    "\n",
    "# Calculate statistics per patient\n",
    "patient_statistics = alarms_per_patient.describe()\n",
    "\n",
    "# Print alarms per patient\n",
    "print(\"Alarms per Patient:\")\n",
    "print(alarms_per_patient)\n",
    "\n",
    "# Print descriptive statistics for alarms per patient\n",
    "print(\"\\nStatistics for Alarms per Patient:\")\n",
    "print(patient_statistics)\n",
    "# Save descriptive statistics to an Excel file\n",
    "alarms_per_patient.to_excel(\"patient_statistics.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% PATIENTWITH CRITICAL ILLNESS EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patient_id signal  threshold           start_time  \\\n",
      "0         B-N-0001  ECGRR       50.0  2022-07-12 10:06:26   \n",
      "1         B-N-0001  ECGRR       50.0  2022-07-12 10:06:34   \n",
      "2         B-N-0001  ECGRR       50.0  2022-07-12 10:06:55   \n",
      "3         B-N-0001  ECGRR       50.0  2022-07-12 10:07:05   \n",
      "4         B-N-0001   SPO2       90.0  2022-07-12 10:07:18   \n",
      "...            ...    ...        ...                  ...   \n",
      "2741837   Z-H-0387  ECGRR       40.0  2023-07-02 12:00:53   \n",
      "2741838   Z-H-0387  ECGRR       40.0  2023-07-02 12:01:55   \n",
      "2741839   Z-H-0387  ECGRR       40.0  2023-07-02 12:02:46   \n",
      "2741840   Z-H-0387  ECGRR       40.0  2023-07-02 12:03:24   \n",
      "2741841   Z-H-0387  ECGRR       40.0  2023-07-02 12:04:49   \n",
      "\n",
      "                    end_time  duration  value  count  \\\n",
      "0        2022-07-12 10:06:27       1.0   69.0    2.0   \n",
      "1        2022-07-12 10:06:52      18.0   77.0   19.0   \n",
      "2        2022-07-12 10:06:56       1.0   56.0    2.0   \n",
      "3        2022-07-12 10:09:30     145.0   53.0  145.0   \n",
      "4        2022-07-12 10:12:30     312.0   84.0  310.0   \n",
      "...                      ...       ...    ...    ...   \n",
      "2741837  2023-07-02 12:01:12      19.0   41.0   21.0   \n",
      "2741838  2023-07-02 12:02:02       7.0   43.0    8.0   \n",
      "2741839  2023-07-02 12:02:53       7.0   44.0    8.0   \n",
      "2741840  2023-07-02 12:03:31       7.0   43.0    8.0   \n",
      "2741841  2023-07-02 12:04:59      10.0   43.0   11.0   \n",
      "\n",
      "        (Q28) New Critical Illness Event During hospitalization (CIE)  \\\n",
      "0                                                      NaN              \n",
      "1                                                      NaN              \n",
      "2                                                      NaN              \n",
      "3                                                      NaN              \n",
      "4                                                      NaN              \n",
      "...                                                    ...              \n",
      "2741837                                                NaN              \n",
      "2741838                                                NaN              \n",
      "2741839                                                NaN              \n",
      "2741840                                                NaN              \n",
      "2741841                                                NaN              \n",
      "\n",
      "         (Q29) Number of critical Illness events during hospitalization (CIE)  \\\n",
      "0                                                      NaN                      \n",
      "1                                                      NaN                      \n",
      "2                                                      NaN                      \n",
      "3                                                      NaN                      \n",
      "4                                                      NaN                      \n",
      "...                                                    ...                      \n",
      "2741837                                                NaN                      \n",
      "2741838                                                NaN                      \n",
      "2741839                                                NaN                      \n",
      "2741840                                                NaN                      \n",
      "2741841                                                NaN                      \n",
      "\n",
      "        Events_Column  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4                 NaN  \n",
      "...               ...  \n",
      "2741837           NaN  \n",
      "2741838           NaN  \n",
      "2741839           NaN  \n",
      "2741840           NaN  \n",
      "2741841           NaN  \n",
      "\n",
      "[1204359 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provided list of patient IDs\n",
    "patient_ids = [\n",
    "    'B-N-0001', 'B-N-0003', 'B-N-0006','B-N-0007', 'B-N-0009', 'B-N-0017', 'B-N-0021', 'B-N-0025',  'B-N-0029',  'B-N-0038',\n",
    "    'B-N-0039', 'B-N-0041', 'B-N-0048', 'B-N-0050', 'B-N-0054', 'B-N-0057', 'B-N-0058', 'B-N-0059','B-N-0066', 'B-N-0072', 'B-N-0073', 'B-N-0074', 'B-N-0075', 'B-N-0076', 'B-N-0081','B-N-0083', 'B-N-0084', 'B-N-0085', 'B-N-0086', 'B-N-0088', 'B-N-0089', 'B-N-0091', 'B-S-0005', \n",
    "    'B-S-0013', 'B-S-0014', 'B-S-0017', 'B-S-0022','B-S-0027', 'B-S-0034', 'B-S-0039',\n",
    "    'B-S-0060', 'B-S-0064', 'B-S-0073', 'B-S-0074', 'B-S-0075', 'B-S-0076', 'B-S-0082', 'B-S-0084',\n",
    "    'B-S-0086', 'B-S-0090', 'B-S-0093', 'B-S-0096', 'B-S-0097', 'B-S-0102',\n",
    "    'B-S-0104', 'B-S-0110',  'B-S-0111', 'B-S-0117', 'B-S-0122', 'B-S-0125', 'B-S-0137', 'B-S-0148',\n",
    "    'B-S-0150', 'B-S-0154', 'B-S-0155', 'B-S-0167', 'B-S-0168', 'B-S-0169', 'B-S-0183', 'B-S-0192', 'B-S-0193',\n",
    "    'B-S-0209', 'B-S-0213', 'B-S-0222', 'B-S-0223', 'B-S-0228', 'B-S-0235', 'B-S-0239', 'B-S-0242', 'B-S-0250', 'B-S-0252', 'B-S-0259',\n",
    "    'B-S-0267', 'B-S-0269', 'B-S-0270', 'B-S-0271', 'B-S-0276', 'B-S-0277', 'B-S-0278', 'B-S-0282',  'B-S-0283', 'B-S-0283', 'B-S-0284',\n",
    "    'B-S-0292', 'B-S-0299', 'Z-H-0001', 'Z-H-0002', 'Z-H-0003', 'Z-H-0004',  'Z-H-0007', 'Z-H-0008', 'Z-H-0009', 'Z-H-0010', 'Z-H-0018', \n",
    "    'Z-H-0022', 'Z-H-0024', 'Z-H-0025', 'Z-H-0029', 'Z-H-0030', 'Z-H-0032','Z-H-0032',  'Z-H-0033', 'Z-H-0035', 'Z-H-0036', 'Z-H-0043', 'Z-H-0046', 'Z-H-0047',\n",
    "    'Z-H-0052', 'Z-H-0053', 'Z-H-0054',  'Z-H-0058', 'Z-H-0062', 'Z-H-0064', 'Z-H-0067', 'Z-H-0074', 'Z-H-0078', 'Z-H-0080',  'Z-H-0083', 'Z-H-0084', \n",
    "    'Z-H-0089', 'Z-H-0092', 'Z-H-0094', 'Z-H-0098',  'Z-H-0103', 'Z-H-0108', 'Z-H-0108', 'Z-H-0109',\n",
    "    'Z-H-0112', 'Z-H-0114', 'Z-H-0114',   'Z-H-0116', 'Z-H-0120','Z-H-0120',  'Z-H-0122', 'Z-H-0122', 'Z-H-0123', 'Z-H-0124', 'Z-H-0124', 'Z-H-0126',\n",
    "    'Z-H-0130',  'Z-H-0131', 'Z-H-0135', 'Z-H-0137',  'Z-H-0141','Z-H-0144', 'Z-H-0146', 'Z-H-0149', 'Z-H-0154', 'Z-H-0157','Z-H-0161',  'Z-H-0162', 'Z-H-0165', 'Z-H-0166', 'Z-H-0179', 'Z-H-0180',\n",
    "    'Z-H-0180',  'Z-H-0183', 'Z-H-0185',  'Z-H-0188', 'Z-H-0189','Z-H-0193', 'Z-H-0196', 'Z-H-0198', 'Z-H-0200', 'Z-H-0204', 'Z-H-0208',\n",
    "    'Z-H-0210',  'Z-H-0216', 'Z-H-0222', 'Z-H-0223', 'Z-H-0225', 'Z-H-0226', 'Z-H-0226', 'Z-H-0228','Z-H-0231', 'Z-H-0233', 'Z-H-0238', 'Z-H-0242', 'Z-H-0243', 'Z-H-0243', 'Z-H-0244', 'Z-H-0245', 'Z-H-0245',\n",
    "    'Z-H-0249',  'Z-H-0250', 'Z-H-0258', 'Z-H-0261', 'Z-H-0262', 'Z-H-0264',\n",
    "    'Z-H-0265', 'Z-H-0268', 'Z-H-0269',  'Z-H-0270','Z-H-0272', 'Z-H-0275', 'Z-H-0276', 'Z-H-0280', 'Z-H-0283', 'Z-H-0292',  'Z-H-0296',\n",
    "    'Z-H-0300', 'Z-H-0301', 'Z-H-0302', 'Z-H-0304', 'Z-H-0306', 'Z-H-0308', 'Z-H-0310',\n",
    "    'Z-H-0312', 'Z-H-0316', 'Z-H-0317', 'Z-H-0318',  'Z-H-0320', 'Z-H-0320',\n",
    "    'Z-H-0320', 'Z-H-0321',  'Z-H-0323', 'Z-H-0324', 'Z-H-0332', 'Z-H-0333', \n",
    "    'Z-H-0335', 'Z-H-0336', 'Z-H-0338', 'Z-H-0339',  'Z-H-0341', 'Z-H-0344', 'Z-H-0346', \n",
    "    'Z-H-0348', 'Z-H-0350', 'Z-H-0352', 'Z-H-0357',  'Z-H-0358', 'Z-H-0362', 'Z-H-0363',\n",
    "    'Z-H-0364', 'Z-H-0365', 'Z-H-0366', 'Z-H-0367', 'Z-H-0374', 'Z-H-0383',  'Z-H-0384',\n",
    "    'Z-H-0385', 'Z-H-0386', 'Z-H-0387'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to keep only the specified patient IDs\n",
    "df = df[df['patient_id'].isin(patient_ids)]\n",
    "\n",
    "# Now, filtered_data contains only the data of the specified patients\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%AGE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df and df2 are your DataFrames\n",
    "df = pd.merge(df, df2, on='patient_id', how='inner')\n",
    "df.to_csv('alldataage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>signal</th>\n",
       "      <th>threshold</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "      <th>(Q28) New Critical Illness Event During hospitalization (CIE)</th>\n",
       "      <th>(Q29) Number of critical Illness events during hospitalization (CIE)</th>\n",
       "      <th>...</th>\n",
       "      <th>RR2_threshold_x</th>\n",
       "      <th>Age_months_y</th>\n",
       "      <th>Sex_y</th>\n",
       "      <th>age_group_y</th>\n",
       "      <th>HR_threshold_y</th>\n",
       "      <th>SpO2_threshold_y</th>\n",
       "      <th>RR_threshold_y</th>\n",
       "      <th>HR2_threshold_y</th>\n",
       "      <th>SpO22_threshold_y</th>\n",
       "      <th>RR2_threshold_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:06:26</td>\n",
       "      <td>2022-07-12 10:06:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:06:34</td>\n",
       "      <td>2022-07-12 10:06:52</td>\n",
       "      <td>18.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:06:55</td>\n",
       "      <td>2022-07-12 10:06:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-07-12 10:07:05</td>\n",
       "      <td>2022-07-12 10:09:30</td>\n",
       "      <td>145.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-N-0001</td>\n",
       "      <td>SPO2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2022-07-12 10:07:18</td>\n",
       "      <td>2022-07-12 10:12:30</td>\n",
       "      <td>312.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-11 Months</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530718</th>\n",
       "      <td>Z-H-0386</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-06-30 11:52:20</td>\n",
       "      <td>2023-06-30 11:52:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530719</th>\n",
       "      <td>Z-H-0386</td>\n",
       "      <td>SPO2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2023-06-30 11:52:22</td>\n",
       "      <td>2023-06-30 11:57:05</td>\n",
       "      <td>283.0</td>\n",
       "      <td>89.992278</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530720</th>\n",
       "      <td>Z-H-0386</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-06-30 11:53:31</td>\n",
       "      <td>2023-06-30 11:53:40</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530721</th>\n",
       "      <td>Z-H-0386</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-06-30 11:54:18</td>\n",
       "      <td>2023-06-30 11:54:22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530722</th>\n",
       "      <td>Z-H-0386</td>\n",
       "      <td>ECGRR</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2023-06-30 11:56:48</td>\n",
       "      <td>2023-06-30 11:57:17</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>Male</td>\n",
       "      <td>PED - 1-4 Years</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530723 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id signal  threshold           start_time             end_time  \\\n",
       "0        B-N-0001  ECGRR       50.0  2022-07-12 10:06:26  2022-07-12 10:06:27   \n",
       "1        B-N-0001  ECGRR       50.0  2022-07-12 10:06:34  2022-07-12 10:06:52   \n",
       "2        B-N-0001  ECGRR       50.0  2022-07-12 10:06:55  2022-07-12 10:06:56   \n",
       "3        B-N-0001  ECGRR       50.0  2022-07-12 10:07:05  2022-07-12 10:09:30   \n",
       "4        B-N-0001   SPO2       90.0  2022-07-12 10:07:18  2022-07-12 10:12:30   \n",
       "...           ...    ...        ...                  ...                  ...   \n",
       "530718   Z-H-0386  ECGRR       40.0  2023-06-30 11:52:20  2023-06-30 11:52:30   \n",
       "530719   Z-H-0386   SPO2       90.0  2023-06-30 11:52:22  2023-06-30 11:57:05   \n",
       "530720   Z-H-0386  ECGRR       40.0  2023-06-30 11:53:31  2023-06-30 11:53:40   \n",
       "530721   Z-H-0386  ECGRR       40.0  2023-06-30 11:54:18  2023-06-30 11:54:22   \n",
       "530722   Z-H-0386  ECGRR       40.0  2023-06-30 11:56:48  2023-06-30 11:57:17   \n",
       "\n",
       "        duration      value  count  \\\n",
       "0            1.0  69.000000    2.0   \n",
       "1           18.0  77.000000   19.0   \n",
       "2            1.0  56.000000    2.0   \n",
       "3          145.0  53.000000  145.0   \n",
       "4          312.0  84.000000  310.0   \n",
       "...          ...        ...    ...   \n",
       "530718      10.0  42.000000   11.0   \n",
       "530719     283.0  89.992278   25.0   \n",
       "530720       9.0  45.000000   10.0   \n",
       "530721       4.0  42.000000    5.0   \n",
       "530722      29.0  44.000000   29.0   \n",
       "\n",
       "       (Q28) New Critical Illness Event During hospitalization (CIE)  \\\n",
       "0                                                     NaN              \n",
       "1                                                     NaN              \n",
       "2                                                     NaN              \n",
       "3                                                     NaN              \n",
       "4                                                     NaN              \n",
       "...                                                   ...              \n",
       "530718                                                NaN              \n",
       "530719                                                NaN              \n",
       "530720                                                NaN              \n",
       "530721                                                NaN              \n",
       "530722                                                NaN              \n",
       "\n",
       "        (Q29) Number of critical Illness events during hospitalization (CIE)  \\\n",
       "0                                                     NaN                      \n",
       "1                                                     NaN                      \n",
       "2                                                     NaN                      \n",
       "3                                                     NaN                      \n",
       "4                                                     NaN                      \n",
       "...                                                   ...                      \n",
       "530718                                                NaN                      \n",
       "530719                                                NaN                      \n",
       "530720                                                NaN                      \n",
       "530721                                                NaN                      \n",
       "530722                                                NaN                      \n",
       "\n",
       "        ... RR2_threshold_x  Age_months_y Sex_y        age_group_y  \\\n",
       "0       ...              70      3.100000  Male  PED - 1-11 Months   \n",
       "1       ...              70      3.100000  Male  PED - 1-11 Months   \n",
       "2       ...              70      3.100000  Male  PED - 1-11 Months   \n",
       "3       ...              70      3.100000  Male  PED - 1-11 Months   \n",
       "4       ...              70      3.100000  Male  PED - 1-11 Months   \n",
       "...     ...             ...           ...   ...                ...   \n",
       "530718  ...              60     46.799999  Male    PED - 1-4 Years   \n",
       "530719  ...              60     46.799999  Male    PED - 1-4 Years   \n",
       "530720  ...              60     46.799999  Male    PED - 1-4 Years   \n",
       "530721  ...              60     46.799999  Male    PED - 1-4 Years   \n",
       "530722  ...              60     46.799999  Male    PED - 1-4 Years   \n",
       "\n",
       "        HR_threshold_y  SpO2_threshold_y  RR_threshold_y  HR2_threshold_y  \\\n",
       "0                  180                90              50              200   \n",
       "1                  180                90              50              200   \n",
       "2                  180                90              50              200   \n",
       "3                  180                90              50              200   \n",
       "4                  180                90              50              200   \n",
       "...                ...               ...             ...              ...   \n",
       "530718             150                90              40              190   \n",
       "530719             150                90              40              190   \n",
       "530720             150                90              40              190   \n",
       "530721             150                90              40              190   \n",
       "530722             150                90              40              190   \n",
       "\n",
       "        SpO22_threshold_y  RR2_threshold_y  \n",
       "0                     100               70  \n",
       "1                     100               70  \n",
       "2                     100               70  \n",
       "3                     100               70  \n",
       "4                     100               70  \n",
       "...                   ...              ...  \n",
       "530718                100               60  \n",
       "530719                100               60  \n",
       "530720                100               60  \n",
       "530721                100               60  \n",
       "530722                100               60  \n",
       "\n",
       "[530723 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       patient_id signal  threshold           start_time             end_time  \\\n",
      "1        B-N-0001  ECGRR       50.0  2022-07-12 10:06:34  2022-07-12 10:06:52   \n",
      "122      B-N-0001  ECGRR       50.0  2022-07-13 04:20:37  2022-07-13 04:22:44   \n",
      "126      B-N-0001  ECGRR       50.0  2022-07-13 04:37:22  2022-07-13 04:37:24   \n",
      "182      B-N-0001  ECGRR       50.0  2022-07-13 08:19:37  2022-07-13 08:20:07   \n",
      "211      B-N-0001  ECGRR       50.0  2022-07-13 08:42:28  2022-07-13 08:42:39   \n",
      "...           ...    ...        ...                  ...                  ...   \n",
      "530489   Z-H-0386  ECGRR       40.0  2023-06-30 06:35:28  2023-06-30 06:35:29   \n",
      "530490   Z-H-0386  ECGRR       40.0  2023-06-30 06:35:32  2023-06-30 06:35:37   \n",
      "530492   Z-H-0386  ECGRR       40.0  2023-06-30 06:36:29  2023-06-30 06:36:30   \n",
      "530505   Z-H-0386  ECGRR       40.0  2023-06-30 06:51:02  2023-06-30 06:51:31   \n",
      "530610   Z-H-0386  ECGRR       40.0  2023-06-30 09:16:15  2023-06-30 09:16:23   \n",
      "\n",
      "        duration  value  count  \\\n",
      "1           18.0   77.0   19.0   \n",
      "122        127.0   71.0  127.0   \n",
      "126          2.0   79.0    3.0   \n",
      "182         30.0   79.0   31.0   \n",
      "211         11.0   82.0   12.0   \n",
      "...          ...    ...    ...   \n",
      "530489       1.0   85.0    2.0   \n",
      "530490       5.0   83.0    6.0   \n",
      "530492       1.0   81.0    2.0   \n",
      "530505      29.0   63.0   30.0   \n",
      "530610       8.0   61.0    9.0   \n",
      "\n",
      "       (Q28) New Critical Illness Event During hospitalization (CIE)  \\\n",
      "1                                                     NaN              \n",
      "122                                                   NaN              \n",
      "126                                                   NaN              \n",
      "182                                                   NaN              \n",
      "211                                                   NaN              \n",
      "...                                                   ...              \n",
      "530489                                                NaN              \n",
      "530490                                                NaN              \n",
      "530492                                                NaN              \n",
      "530505                                                NaN              \n",
      "530610                                                NaN              \n",
      "\n",
      "        (Q29) Number of critical Illness events during hospitalization (CIE)  \\\n",
      "1                                                     NaN                      \n",
      "122                                                   NaN                      \n",
      "126                                                   NaN                      \n",
      "182                                                   NaN                      \n",
      "211                                                   NaN                      \n",
      "...                                                   ...                      \n",
      "530489                                                NaN                      \n",
      "530490                                                NaN                      \n",
      "530492                                                NaN                      \n",
      "530505                                                NaN                      \n",
      "530610                                                NaN                      \n",
      "\n",
      "        ... RR2_threshold_x  Age_months_y Sex_y        age_group_y  \\\n",
      "1       ...              70      3.100000  Male  PED - 1-11 Months   \n",
      "122     ...              70      3.100000  Male  PED - 1-11 Months   \n",
      "126     ...              70      3.100000  Male  PED - 1-11 Months   \n",
      "182     ...              70      3.100000  Male  PED - 1-11 Months   \n",
      "211     ...              70      3.100000  Male  PED - 1-11 Months   \n",
      "...     ...             ...           ...   ...                ...   \n",
      "530489  ...              60     46.799999  Male    PED - 1-4 Years   \n",
      "530490  ...              60     46.799999  Male    PED - 1-4 Years   \n",
      "530492  ...              60     46.799999  Male    PED - 1-4 Years   \n",
      "530505  ...              60     46.799999  Male    PED - 1-4 Years   \n",
      "530610  ...              60     46.799999  Male    PED - 1-4 Years   \n",
      "\n",
      "        HR_threshold_y  SpO2_threshold_y  RR_threshold_y  HR2_threshold_y  \\\n",
      "1                  180                90              50              200   \n",
      "122                180                90              50              200   \n",
      "126                180                90              50              200   \n",
      "182                180                90              50              200   \n",
      "211                180                90              50              200   \n",
      "...                ...               ...             ...              ...   \n",
      "530489             150                90              40              190   \n",
      "530490             150                90              40              190   \n",
      "530492             150                90              40              190   \n",
      "530505             150                90              40              190   \n",
      "530610             150                90              40              190   \n",
      "\n",
      "        SpO22_threshold_y  RR2_threshold_y  \n",
      "1                     100               70  \n",
      "122                   100               70  \n",
      "126                   100               70  \n",
      "182                   100               70  \n",
      "211                   100               70  \n",
      "...                   ...              ...  \n",
      "530489                100               60  \n",
      "530490                100               60  \n",
      "530492                100               60  \n",
      "530505                100               60  \n",
      "530610                100               60  \n",
      "\n",
      "[13772 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert threshold columns to numeric\n",
    "threshold_cols = ['HR2_threshold_y', 'SpO22_threshold_y', 'RR2_threshold_y']\n",
    "for col in threshold_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Filter out rows where the values exceed the thresholds for HR, SpO2, and RR\n",
    "filtered_df = df[((df['signal'] == 'ECGRR') & (df['value'] > df['HR2_threshold_y'])) |\n",
    "                 ((df['signal'] == 'ECGSpO2') & (df['value'] > df['SpO22_threshold_y'])) |\n",
    "                 ((df['signal'] == 'ECGRR') & (df['value'] > df['RR2_threshold_y']))]\n",
    "\n",
    "# Check the filtered DataFrame\n",
    "print(filtered_df)\n",
    "\n",
    "# Export the filtered DataFrame if needed\n",
    "# filtered_df.to_csv(\"filtered_dataset.csv\", index=False)  # Replace \"filtered_dataset.csv\" with your desired file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Counts for Alarms with Duration\n",
      "+----------+---------+\n",
      "| Signal   |   Count |\n",
      "|----------+---------|\n",
      "| SPO2     |       0 |\n",
      "| ECGRR    |   13772 |\n",
      "| ECGHR    |       0 |\n",
      "+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define a list of signals you want to count\n",
    "signals_to_count = ['SPO2', 'ECGRR', 'ECGHR']\n",
    "\n",
    "# Create an empty dictionary to store signal counts\n",
    "signal_counts = {}\n",
    "\n",
    "# Iterate over the list of signals\n",
    "for signal in signals_to_count:\n",
    "    # Count occurrences of the signal in the filtered alarms\n",
    "    signal_count = filtered_df[filtered_df['signal'] == signal].shape[0]\n",
    "    signal_counts[signal] = signal_count\n",
    "\n",
    "# Print the signal counts\n",
    "print(\"Signal Counts for Alarms with Duration\")\n",
    "print(tabulate.tabulate(signal_counts.items(), headers=['Signal', 'Count'], tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Critical_Event_Name Critical_Event_Start_Time  \\\n",
      "0        Respiratory support       2022-08-09 01:43:00   \n",
      "1        Respiratory support       2022-08-09 01:43:00   \n",
      "2          Blood transfusion       2022-09-28 01:43:00   \n",
      "3        Respiratory support       2022-09-28 05:50:00   \n",
      "4        Respiratory support       2022-09-29 10:31:00   \n",
      "..                       ...                       ...   \n",
      "321                   Sepsis       2023-06-28 09:59:00   \n",
      "322        Blood transfusion       2023-06-30 02:10:00   \n",
      "323  Intravenous fluid bolus       2023-06-29 07:00:00   \n",
      "324        Blood transfusion       2023-06-29 09:54:00   \n",
      "325               Convulsion       2023-06-29 09:53:00   \n",
      "\n",
      "     Total_Values_1_Hour_Before_Event  Total_Values_2_Hours_Before_Event  \\\n",
      "0                            0.000000                           0.000000   \n",
      "1                            0.000000                           0.000000   \n",
      "2                         8004.833333                        8433.833333   \n",
      "3                         6554.500000                        5095.000000   \n",
      "4                         7823.500000                       13440.291280   \n",
      "..                                ...                                ...   \n",
      "321                      11862.000000                        7950.000000   \n",
      "322                      15501.053279                       21089.000000   \n",
      "323                       6184.000000                        7287.000000   \n",
      "324                       9462.042254                       12404.200000   \n",
      "325                       9293.042254                       12420.200000   \n",
      "\n",
      "     Total_Values_3_Hours_Before_Event  \n",
      "0                             0.000000  \n",
      "1                             0.000000  \n",
      "2                          6865.952381  \n",
      "3                          8366.500000  \n",
      "4                          8323.000000  \n",
      "..                                 ...  \n",
      "321                        6857.000000  \n",
      "322                       27809.200000  \n",
      "323                        8468.136905  \n",
      "324                       13585.948020  \n",
      "325                       13527.948020  \n",
      "\n",
      "[326 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named df\n",
    "\n",
    "# Step 1: Filter rows where critical illness events occur\n",
    "critical_events = df[df['Events_Column'].notna()]\n",
    "\n",
    "# Step 2: Calculate total values before each critical illness event within different time intervals\n",
    "totals_before_event = []\n",
    "for index, event in critical_events.iterrows():\n",
    "    event_time = pd.to_datetime(event['start_time'])\n",
    "    one_hour_before_event = event_time - timedelta(hours=1)\n",
    "    two_hours_before_event = event_time - timedelta(hours=2)\n",
    "    three_hours_before_event = event_time - timedelta(hours=3)\n",
    "    \n",
    "    # Calculate total values within 1 hour before the event\n",
    "    values_within_1_hour = df[(df['start_time'] >= one_hour_before_event) & (df['start_time'] < event_time) & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 2 hours before the event, excluding values within 1 hour\n",
    "    values_within_2_hours = df[(df['start_time'] >= two_hours_before_event) & (df['start_time'] < event_time) & (df['value'].notna()) & (df['start_time'] < one_hour_before_event)]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 3 hours before the event, excluding values within 2 hours\n",
    "    values_within_3_hours = df[(df['start_time'] >= three_hours_before_event) & (df['start_time'] < event_time) & (df['value'].notna()) & (df['start_time'] < two_hours_before_event)]['value'].sum()\n",
    "    \n",
    "    totals_before_event.append({\n",
    "        'Critical_Event_Name': event['Events_Column'],  # Adding the critical event name\n",
    "        'Critical_Event_Start_Time': event['start_time'],\n",
    "        'Total_Values_1_Hour_Before_Event': values_within_1_hour,\n",
    "        'Total_Values_2_Hours_Before_Event': values_within_2_hours,\n",
    "        'Total_Values_3_Hours_Before_Event': values_within_3_hours\n",
    "    })\n",
    "\n",
    "# Step 3: Create a new DataFrame to summarize the results\n",
    "summary_df = pd.DataFrame(totals_before_event)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_excel('summary before.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRITICAL ILLNESS EVENTS WITH 15 SECONDS DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Critical_Event_Name Critical_Event_Start_Time  \\\n",
      "0        Respiratory support       2022-08-09 01:43:00   \n",
      "1        Respiratory support       2022-08-09 01:43:00   \n",
      "2          Blood transfusion       2022-09-28 01:43:00   \n",
      "3        Respiratory support       2022-09-28 05:50:00   \n",
      "4        Respiratory support       2022-09-29 10:31:00   \n",
      "..                       ...                       ...   \n",
      "321                   Sepsis       2023-06-28 09:59:00   \n",
      "322        Blood transfusion       2023-06-30 02:10:00   \n",
      "323  Intravenous fluid bolus       2023-06-29 07:00:00   \n",
      "324        Blood transfusion       2023-06-29 09:54:00   \n",
      "325               Convulsion       2023-06-29 09:53:00   \n",
      "\n",
      "     Total_Values_1_Hour_Before_Event  Total_Values_2_Hours_Before_Event  \\\n",
      "0                            0.000000                            0.00000   \n",
      "1                            0.000000                            0.00000   \n",
      "2                         2685.833333                         2801.50000   \n",
      "3                         1500.500000                         1217.00000   \n",
      "4                         4183.000000                         6798.79128   \n",
      "..                                ...                                ...   \n",
      "321                       4673.000000                         3693.00000   \n",
      "322                       4838.803279                         7522.00000   \n",
      "323                       1897.000000                         2931.00000   \n",
      "324                       3734.042254                         4702.00000   \n",
      "325                       3647.042254                         4718.00000   \n",
      "\n",
      "     Total_Values_3_Hours_Before_Event  \n",
      "0                             0.000000  \n",
      "1                             0.000000  \n",
      "2                          2030.952381  \n",
      "3                          3182.000000  \n",
      "4                          3116.000000  \n",
      "..                                 ...  \n",
      "321                        2629.000000  \n",
      "322                       12918.000000  \n",
      "323                        3675.136905  \n",
      "324                        5429.948020  \n",
      "325                        5371.948020  \n",
      "\n",
      "[326 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named df\n",
    "\n",
    "# Step 1: Filter rows where critical illness events occur\n",
    "critical_events = df[df['Events_Column'].notna()]\n",
    "\n",
    "# Step 2: Calculate total values before each critical illness event within different time intervals\n",
    "totals_before_event = []\n",
    "for index, event in critical_events.iterrows():\n",
    "    event_time = pd.to_datetime(event['start_time'])\n",
    "    one_hour_before_event = event_time - timedelta(hours=1)\n",
    "    two_hours_before_event = event_time - timedelta(hours=2)\n",
    "    three_hours_before_event = event_time - timedelta(hours=3)\n",
    "    \n",
    "    # Calculate total values within 1 hour before the event with durations greater than 15 seconds\n",
    "    values_within_1_hour = df[(df['start_time'] >= one_hour_before_event) & (df['start_time'] < event_time) & (df['value'].notna()) & (df['duration'] > 15)]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 2 hours before the event with durations greater than 15 seconds, excluding values within 1 hour\n",
    "    values_within_2_hours = df[(df['start_time'] >= two_hours_before_event) & (df['start_time'] < event_time) & (df['value'].notna()) & (df['duration'] > 15) & (df['start_time'] < one_hour_before_event)]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 3 hours before the event with durations greater than 15 seconds, excluding values within 2 hours\n",
    "    values_within_3_hours = df[(df['start_time'] >= three_hours_before_event) & (df['start_time'] < event_time) & (df['value'].notna()) & (df['duration'] > 15) & (df['start_time'] < two_hours_before_event)]['value'].sum()\n",
    "    \n",
    "    totals_before_event.append({\n",
    "        'Critical_Event_Name': event['Events_Column'],  # Adding the critical event name\n",
    "        'Critical_Event_Start_Time': event['start_time'],\n",
    "        'Total_Values_1_Hour_Before_Event': values_within_1_hour,\n",
    "        'Total_Values_2_Hours_Before_Event': values_within_2_hours,\n",
    "        'Total_Values_3_Hours_Before_Event': values_within_3_hours\n",
    "    })\n",
    "\n",
    "# Step 3: Create a new DataFrame to summarize the results\n",
    "summary_df = pd.DataFrame(totals_before_event)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_excel('durationbeforesummary.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9408\\2721178534.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_time'] = pd.to_datetime(df['start_time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Critical_Event_Name Critical_Event_Start_Time  \\\n",
      "0        Respiratory support       2022-08-09 01:43:00   \n",
      "1        Respiratory support       2022-08-09 01:43:00   \n",
      "2          Blood transfusion       2022-09-28 01:43:00   \n",
      "3        Respiratory support       2022-09-28 05:50:00   \n",
      "4        Respiratory support       2022-09-29 10:31:00   \n",
      "..                       ...                       ...   \n",
      "321                   Sepsis       2023-06-28 09:59:00   \n",
      "322        Blood transfusion       2023-06-30 02:10:00   \n",
      "323  Intravenous fluid bolus       2023-06-29 07:00:00   \n",
      "324        Blood transfusion       2023-06-29 09:54:00   \n",
      "325               Convulsion       2023-06-29 09:53:00   \n",
      "\n",
      "     Total_Values_1_Hour_After_Event  Total_Values_2_Hours_After_Event  \\\n",
      "0                         110.000000                          0.000000   \n",
      "1                         110.000000                          0.000000   \n",
      "2                        6854.500000                       7557.499256   \n",
      "3                        7147.462406                       6694.500000   \n",
      "4                       10030.500000                      12129.994604   \n",
      "..                               ...                               ...   \n",
      "321                     11390.000000                       9688.000000   \n",
      "322                     10339.802083                       8149.000000   \n",
      "323                     13708.948020                      13662.200000   \n",
      "324                      9178.007952                       9850.000000   \n",
      "325                      9389.007952                       9779.000000   \n",
      "\n",
      "     Total_Values_3_Hours_After_Event  \n",
      "0                            0.000000  \n",
      "1                            0.000000  \n",
      "2                         5487.500000  \n",
      "3                         6367.125000  \n",
      "4                         9988.100000  \n",
      "..                                ...  \n",
      "321                       7562.000000  \n",
      "322                       8580.000000  \n",
      "323                       8024.042254  \n",
      "324                      12084.000000  \n",
      "325                      12111.000000  \n",
      "\n",
      "[326 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named df\n",
    "\n",
    "# Convert 'start_time' column to Timestamp objects\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "\n",
    "# Step 1: Filter rows where critical illness events occur\n",
    "critical_events = df[df['Events_Column'].notna()]\n",
    "\n",
    "# Step 2: Calculate total values after each critical illness event within different time intervals\n",
    "totals_after_event = []\n",
    "for index, event in critical_events.iterrows():\n",
    "    event_time = event['start_time']\n",
    "    one_hour_after_event = event_time + timedelta(hours=1)\n",
    "    two_hours_after_event = event_time + timedelta(hours=2)\n",
    "    three_hours_after_event = event_time + timedelta(hours=3)\n",
    "    \n",
    "    # Calculate total values within 1 hour after the event\n",
    "    values_within_1_hour = df[(df['start_time'] >= event_time) & (df['start_time'] < one_hour_after_event) & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 2 hours after the event, excluding values within 1 hour\n",
    "    values_within_2_hours = df[(df['start_time'] >= one_hour_after_event) & (df['start_time'] < two_hours_after_event) & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 3 hours after the event, excluding values within 1 and 2 hours\n",
    "    values_within_3_hours = df[(df['start_time'] >= two_hours_after_event) & (df['start_time'] < three_hours_after_event) & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    totals_after_event.append({\n",
    "        'Critical_Event_Name': event['Events_Column'],  # Adding the critical event name\n",
    "        'Critical_Event_Start_Time': event['start_time'],\n",
    "        'Total_Values_1_Hour_After_Event': values_within_1_hour,\n",
    "        'Total_Values_2_Hours_After_Event': values_within_2_hours,\n",
    "        'Total_Values_3_Hours_After_Event': values_within_3_hours\n",
    "    })\n",
    "\n",
    "# Step 3: Create a new DataFrame to summarize the results\n",
    "summary_df = pd.DataFrame(totals_after_event)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_excel('summary after.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9408\\3910875337.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start_time'] = pd.to_datetime(df['start_time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Critical_Event_Name Critical_Event_Start_Time  \\\n",
      "0        Respiratory support       2022-08-09 01:43:00   \n",
      "1        Respiratory support       2022-08-09 01:43:00   \n",
      "2          Blood transfusion       2022-09-28 01:43:00   \n",
      "3        Respiratory support       2022-09-28 05:50:00   \n",
      "4        Respiratory support       2022-09-29 10:31:00   \n",
      "..                       ...                       ...   \n",
      "321                   Sepsis       2023-06-28 09:59:00   \n",
      "322        Blood transfusion       2023-06-30 02:10:00   \n",
      "323  Intravenous fluid bolus       2023-06-29 07:00:00   \n",
      "324        Blood transfusion       2023-06-29 09:54:00   \n",
      "325               Convulsion       2023-06-29 09:53:00   \n",
      "\n",
      "     Total_Values_1_Hour_After_Event  Total_Values_2_Hours_After_Event  \\\n",
      "0                         110.000000                          0.000000   \n",
      "1                         110.000000                          0.000000   \n",
      "2                        3177.500000                       3262.499256   \n",
      "3                        2145.962406                       2797.500000   \n",
      "4                        4586.500000                       4968.494604   \n",
      "..                               ...                               ...   \n",
      "321                      3992.000000                       3287.000000   \n",
      "322                      3207.802083                       4026.000000   \n",
      "323                      5561.948020                       4695.000000   \n",
      "324                      3475.007952                       2465.000000   \n",
      "325                      3604.007952                       2465.000000   \n",
      "\n",
      "     Total_Values_3_Hours_After_Event  \n",
      "0                            0.000000  \n",
      "1                            0.000000  \n",
      "2                         1305.500000  \n",
      "3                         2298.125000  \n",
      "4                         3433.500000  \n",
      "..                                ...  \n",
      "321                       2376.000000  \n",
      "322                       3110.000000  \n",
      "323                       3612.042254  \n",
      "324                       4176.000000  \n",
      "325                       4132.000000  \n",
      "\n",
      "[326 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named df\n",
    "\n",
    "# Convert 'start_time' column to Timestamp objects\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "\n",
    "# Step 1: Filter rows where critical illness events occur\n",
    "critical_events = df[df['Events_Column'].notna()]\n",
    "\n",
    "# Step 2: Calculate total values after each critical illness event within different time intervals\n",
    "totals_after_event = []\n",
    "for index, event in critical_events.iterrows():\n",
    "    event_time = event['start_time']\n",
    "    one_hour_after_event = event_time + timedelta(hours=1)\n",
    "    two_hours_after_event = event_time + timedelta(hours=2)\n",
    "    three_hours_after_event = event_time + timedelta(hours=3)\n",
    "    \n",
    "    # Calculate total values within 1 hour after the event\n",
    "    values_within_1_hour = df[(df['start_time'] >= event_time) & (df['start_time'] < one_hour_after_event) & (df['duration'] > 15)  & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 2 hours after the event, excluding values within 1 hour\n",
    "    values_within_2_hours = df[(df['start_time'] >= one_hour_after_event) & (df['start_time'] < two_hours_after_event) & (df['duration'] > 15)  & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    # Calculate total values within 3 hours after the event, excluding values within 1 and 2 hours\n",
    "    values_within_3_hours = df[(df['start_time'] >= two_hours_after_event) & (df['start_time'] < three_hours_after_event) & (df['duration'] > 15)  & (df['value'].notna())]['value'].sum()\n",
    "    \n",
    "    totals_after_event.append({\n",
    "        'Critical_Event_Name': event['Events_Column'],  # Adding the critical event name\n",
    "        'Critical_Event_Start_Time': event['start_time'],\n",
    "        'Total_Values_1_Hour_After_Event': values_within_1_hour,\n",
    "        'Total_Values_2_Hours_After_Event': values_within_2_hours,\n",
    "        'Total_Values_3_Hours_After_Event': values_within_3_hours\n",
    "    })\n",
    "\n",
    "# Step 3: Create a new DataFrame to summarize the results\n",
    "summary_df = pd.DataFrame(totals_after_event)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_excel('durationaftersummary.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 240\n"
     ]
    }
   ],
   "source": [
    "num_patients = filtered_data['patient_id'].nunique()\n",
    "print(\"Number of patients:\", num_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4628\\1415503830.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4628\\1415503830.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4628\\1415503830.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Statistics:\n",
      "count    7636.000000\n",
      "mean      157.721189\n",
      "std       116.766200\n",
      "min         1.000000\n",
      "25%        72.000000\n",
      "50%       130.000000\n",
      "75%       219.000000\n",
      "max       883.000000\n",
      "dtype: float64\n",
      "\n",
      "Number of Patients per Hour:\n",
      "hour\n",
      "2022-07-08 17:00:00    1\n",
      "2022-07-09 05:00:00    1\n",
      "2022-07-09 08:00:00    1\n",
      "2022-07-09 09:00:00    1\n",
      "2022-07-09 10:00:00    1\n",
      "                      ..\n",
      "2023-07-03 10:00:00    2\n",
      "2023-07-03 11:00:00    1\n",
      "2023-07-03 12:00:00    1\n",
      "2023-07-03 13:00:00    1\n",
      "2023-07-03 14:00:00    1\n",
      "Name: patient_id, Length: 7636, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert start_time to datetime\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "\n",
    "# Round start_time to the nearest hour to create hourly windows\n",
    "filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
    "\n",
    "# Group by hour and count occurrences\n",
    "hourly_counts = filtered_data.groupby('hour').size()\n",
    "\n",
    "# Count the number of unique patient IDs per hour\n",
    "patients_per_hour = filtered_data.groupby('hour')['patient_id'].nunique()\n",
    "\n",
    "# Calculate statistics per hour\n",
    "hourly_statistics = hourly_counts.describe()\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Hourly Statistics:\")\n",
    "print(hourly_statistics)\n",
    "\n",
    "# Print the number of patients per hour\n",
    "print(\"\\nNumber of Patients per Hour:\")\n",
    "print(patients_per_hour)\n",
    "patients_per_hour.to_excel(\"patient_per_hour_cie.xlsx\", header=[\"Alarm Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2688\\2560393467.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2688\\2560393467.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Statistics:\n",
      "count    7636.000000\n",
      "mean      157.720927\n",
      "std       116.766475\n",
      "min         0.000000\n",
      "25%        72.000000\n",
      "50%       130.000000\n",
      "75%       219.000000\n",
      "max       883.000000\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Alarm Counts for Each Hour:\n",
      "hour\n",
      "2022-07-08 17:00:00     1\n",
      "2022-07-09 05:00:00     1\n",
      "2022-07-09 08:00:00    47\n",
      "2022-07-09 09:00:00     9\n",
      "2022-07-09 10:00:00     4\n",
      "                       ..\n",
      "2023-07-03 10:00:00    83\n",
      "2023-07-03 11:00:00    24\n",
      "2023-07-03 12:00:00    51\n",
      "2023-07-03 13:00:00    38\n",
      "2023-07-03 14:00:00    38\n",
      "Name: value, Length: 7636, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2688\\2560393467.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert start_time to datetime\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "\n",
    "# Round start_time to the nearest hour to create hourly windows\n",
    "filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
    "\n",
    "# Group by hour and count the values (number of alarms)\n",
    "hourly_counts = filtered_data.groupby('hour')['value'].count()\n",
    "\n",
    "# Calculate statistics per hour\n",
    "hourly_statistics = hourly_counts.describe()\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Hourly Statistics:\")\n",
    "print(hourly_statistics)\n",
    "\n",
    "# Print alarm counts for each hour\n",
    "print(\"\\nAlarm Counts for Each Hour:\")\n",
    "print(hourly_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6584\\2963933079.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6584\\2963933079.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'filtered_data' DataFrame is defined and 'start_time' column is converted to datetime\n",
    "\n",
    "# Round start_time to the nearest hour to create hourly windows and store the result in the 'hour' column\n",
    "filtered_data['hour'] = filtered_data['start_time'].dt.round('H')\n",
    "\n",
    "# Group by hour and sum the values (number of alarms)\n",
    "hourly_counts = filtered_data.groupby('hour')['value'].count()\n",
    "\n",
    "# Save alarm counts for each hour to an Excel file\n",
    " hourly_counts.to_excel(\"ciehourly_alarm_counts.xlsx\", header=[\"Alarm Count\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarms per Patient:\n",
      "patient_id\n",
      "B-N-0001      711\n",
      "B-N-0003     3576\n",
      "B-N-0006    27651\n",
      "B-N-0007     4390\n",
      "B-N-0009     2623\n",
      "            ...  \n",
      "Z-H-0383     4911\n",
      "Z-H-0384     8192\n",
      "Z-H-0385       95\n",
      "Z-H-0386     1065\n",
      "Z-H-0387     2172\n",
      "Name: value, Length: 240, dtype: int64\n",
      "\n",
      "Statistics for Alarms per Patient:\n",
      "count      240.000000\n",
      "mean      5018.154167\n",
      "std       5961.210539\n",
      "min          0.000000\n",
      "25%       1187.250000\n",
      "50%       2600.500000\n",
      "75%       6306.750000\n",
      "max      29639.000000\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'filtered_data' DataFrame is defined and 'start_time' column is converted to datetime\n",
    "\n",
    "# Group by patient_id and count the values\n",
    "alarms_per_patient = filtered_data.groupby('patient_id')['value'].count()\n",
    "\n",
    "# Calculate statistics per patient\n",
    "patient_statistics = alarms_per_patient.describe()\n",
    "\n",
    "# Print alarms per patient\n",
    "print(\"Alarms per Patient:\")\n",
    "print(alarms_per_patient)\n",
    "\n",
    "# Print descriptive statistics for alarms per patient\n",
    "print(\"\\nStatistics for Alarms per Patient:\")\n",
    "print(patient_statistics)\n",
    "# Save descriptive statistics to an Excel file\n",
    "alarms_per_patient.to_excel(\"ciepatient_statistics.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5340\\3262389830.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['duration_bin'] = pd.cut(filtered_data['duration'], bins=duration_bins, labels=duration_labels, right=False)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5340\\3262389830.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  signal_duration_counts = filtered_data.groupby(['signal', 'duration_bin']).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Counts at Different Duration Ranges:\n",
      "duration_bin   < 10s  10-15s  15-20s  20-30s  30-45s  45-60s  >= 60s\n",
      "signal                                                              \n",
      "ECGHR         135502   20994   15741   15527   11485    6431   20536\n",
      "ECGRR         293069  135935   76065   88512   64688   33355   86402\n",
      "SPO2           31952    8635    6723    8089    6913    4387   24086\n",
      "SPO2HR         51688   10528    7273    8603    7042    4233   19963\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create bins for different duration ranges\n",
    "duration_bins = [0, 10, 15, 20, 30, 45, 60, float('inf')]\n",
    "duration_labels = ['< 10s', '10-15s', '15-20s', '20-30s', '30-45s', '45-60s', '>= 60s']\n",
    "\n",
    "# Categorize the duration into bins\n",
    "filtered_data['duration_bin'] = pd.cut(filtered_data['duration'], bins=duration_bins, labels=duration_labels, right=False)\n",
    "\n",
    "# Group by signal and duration bin, then count occurrences\n",
    "signal_duration_counts = filtered_data.groupby(['signal', 'duration_bin']).size().unstack(fill_value=0)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Signal Counts at Different Duration Ranges:\")\n",
    "print(signal_duration_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1988\\3670683058.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for events_column_ Blood transfusion:\n",
      "                                   OLS Regression Results                                   \n",
      "============================================================================================\n",
      "Dep. Variable:     events_column_ Blood transfusion   R-squared:                       0.001\n",
      "Model:                                          OLS   Adj. R-squared:                 -0.002\n",
      "Method:                               Least Squares   F-statistic:                    0.3589\n",
      "Date:                              Fri, 26 Apr 2024   Prob (F-statistic):              0.550\n",
      "Time:                                      10:44:20   Log-Likelihood:                 352.79\n",
      "No. Observations:                               259   AIC:                            -701.6\n",
      "Df Residuals:                                   257   BIC:                            -694.5\n",
      "Df Model:                                         1                                         \n",
      "Covariance Type:                          nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0039      0.004      0.999      0.319      -0.004       0.011\n",
      "x1            -0.0023      0.004     -0.599      0.550      -0.010       0.005\n",
      "==============================================================================\n",
      "Omnibus:                      587.761   Durbin-Watson:                   2.008\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           703339.050\n",
      "Skew:                          15.966   Prob(JB):                         0.00\n",
      "Kurtosis:                     256.288   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Blood transfusion:\n",
      "                                   OLS Regression Results                                  \n",
      "===========================================================================================\n",
      "Dep. Variable:     events_column_Blood transfusion   R-squared:                       0.000\n",
      "Model:                                         OLS   Adj. R-squared:                 -0.004\n",
      "Method:                              Least Squares   F-statistic:                   0.02244\n",
      "Date:                             Fri, 26 Apr 2024   Prob (F-statistic):              0.881\n",
      "Time:                                     10:44:20   Log-Likelihood:                -98.405\n",
      "No. Observations:                              259   AIC:                             200.8\n",
      "Df Residuals:                                  257   BIC:                             207.9\n",
      "Df Model:                                        1                                         \n",
      "Covariance Type:                         nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1467      0.022      6.648      0.000       0.103       0.190\n",
      "x1             0.0033      0.022      0.150      0.881      -0.040       0.047\n",
      "==============================================================================\n",
      "Omnibus:                       98.637   Durbin-Watson:                   1.786\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              214.708\n",
      "Skew:                           1.997   Prob(JB):                     2.38e-47\n",
      "Kurtosis:                       4.987   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Coma:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     events_column_Coma   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.004\n",
      "Method:                 Least Squares   F-statistic:                  0.006942\n",
      "Date:                Fri, 26 Apr 2024   Prob (F-statistic):              0.934\n",
      "Time:                        10:44:20   Log-Likelihood:                 36.456\n",
      "No. Observations:                 259   AIC:                            -68.91\n",
      "Df Residuals:                     257   BIC:                            -61.80\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0463      0.013      3.534      0.000       0.021       0.072\n",
      "x1            -0.0011      0.013     -0.083      0.934      -0.027       0.025\n",
      "==============================================================================\n",
      "Omnibus:                      253.445   Durbin-Watson:                   1.923\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3789.103\n",
      "Skew:                           4.316   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.631   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Convulsion:\n",
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     events_column_Convulsion   R-squared:                       0.002\n",
      "Model:                                  OLS   Adj. R-squared:                 -0.001\n",
      "Method:                       Least Squares   F-statistic:                    0.6255\n",
      "Date:                      Fri, 26 Apr 2024   Prob (F-statistic):              0.430\n",
      "Time:                              10:44:20   Log-Likelihood:                -103.57\n",
      "No. Observations:                       259   AIC:                             211.1\n",
      "Df Residuals:                           257   BIC:                             218.2\n",
      "Df Model:                                 1                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1544      0.023      6.860      0.000       0.110       0.199\n",
      "x1             0.0178      0.023      0.791      0.430      -0.027       0.062\n",
      "==============================================================================\n",
      "Omnibus:                       91.356   Durbin-Watson:                   2.080\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              186.300\n",
      "Skew:                           1.906   Prob(JB):                     3.51e-41\n",
      "Kurtosis:                       4.652   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Death:\n",
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     events_column_Death   R-squared:                       0.014\n",
      "Model:                             OLS   Adj. R-squared:                  0.011\n",
      "Method:                  Least Squares   F-statistic:                     3.778\n",
      "Date:                 Fri, 26 Apr 2024   Prob (F-statistic):             0.0530\n",
      "Time:                         10:44:20   Log-Likelihood:                -62.711\n",
      "No. Observations:                  259   AIC:                             129.4\n",
      "Df Residuals:                      257   BIC:                             136.5\n",
      "Df Model:                            1                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1081      0.019      5.622      0.000       0.070       0.146\n",
      "x1            -0.0374      0.019     -1.944      0.053      -0.075       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      136.997   Durbin-Watson:                   2.040\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              455.403\n",
      "Skew:                           2.467   Prob(JB):                     1.29e-99\n",
      "Kurtosis:                       7.225   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_ICU:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      events_column_ICU   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.003\n",
      "Method:                 Least Squares   F-statistic:                    0.3066\n",
      "Date:                Fri, 26 Apr 2024   Prob (F-statistic):              0.580\n",
      "Time:                        10:44:20   Log-Likelihood:                 103.81\n",
      "No. Observations:                 259   AIC:                            -203.6\n",
      "Df Residuals:                     257   BIC:                            -196.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0270      0.010      2.673      0.008       0.007       0.047\n",
      "x1             0.0056      0.010      0.554      0.580      -0.014       0.026\n",
      "==============================================================================\n",
      "Omnibus:                      323.572   Durbin-Watson:                   1.910\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12486.126\n",
      "Skew:                           5.823   Prob(JB):                         0.00\n",
      "Kurtosis:                      34.959   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_IV or enteral:\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:     events_column_IV or enteral   R-squared:                       0.005\n",
      "Model:                                     OLS   Adj. R-squared:                  0.001\n",
      "Method:                          Least Squares   F-statistic:                     1.377\n",
      "Date:                         Fri, 26 Apr 2024   Prob (F-statistic):              0.242\n",
      "Time:                                 10:44:20   Log-Likelihood:                 264.04\n",
      "No. Observations:                          259   AIC:                            -524.1\n",
      "Df Residuals:                              257   BIC:                            -517.0\n",
      "Df Model:                                    1                                         \n",
      "Covariance Type:                     nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0077      0.005      1.418      0.157      -0.003       0.018\n",
      "x1             0.0064      0.005      1.173      0.242      -0.004       0.017\n",
      "==============================================================================\n",
      "Omnibus:                      489.197   Durbin-Watson:                   2.028\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           169220.833\n",
      "Skew:                          11.159   Prob(JB):                         0.00\n",
      "Kurtosis:                     126.218   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Inotropic support:\n",
      "                                   OLS Regression Results                                  \n",
      "===========================================================================================\n",
      "Dep. Variable:     events_column_Inotropic support   R-squared:                       0.005\n",
      "Model:                                         OLS   Adj. R-squared:                  0.001\n",
      "Method:                              Least Squares   F-statistic:                     1.355\n",
      "Date:                             Fri, 26 Apr 2024   Prob (F-statistic):              0.245\n",
      "Time:                                     10:44:20   Log-Likelihood:                 264.03\n",
      "No. Observations:                              259   AIC:                            -524.1\n",
      "Df Residuals:                                  257   BIC:                            -516.9\n",
      "Df Model:                                        1                                         \n",
      "Covariance Type:                         nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0077      0.005      1.418      0.157      -0.003       0.018\n",
      "x1            -0.0063      0.005     -1.164      0.245      -0.017       0.004\n",
      "==============================================================================\n",
      "Omnibus:                      489.177   Durbin-Watson:                   2.007\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           169107.542\n",
      "Skew:                          11.158   Prob(JB):                         0.00\n",
      "Kurtosis:                     126.175   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Intravenous fluid bolus:\n",
      "                                      OLS Regression Results                                     \n",
      "=================================================================================================\n",
      "Dep. Variable:     events_column_Intravenous fluid bolus   R-squared:                       0.000\n",
      "Model:                                               OLS   Adj. R-squared:                 -0.003\n",
      "Method:                                    Least Squares   F-statistic:                    0.1112\n",
      "Date:                                   Fri, 26 Apr 2024   Prob (F-statistic):              0.739\n",
      "Time:                                           10:44:20   Log-Likelihood:                 1.3677\n",
      "No. Observations:                                    259   AIC:                             1.265\n",
      "Df Residuals:                                        257   BIC:                             8.378\n",
      "Df Model:                                              1                                         \n",
      "Covariance Type:                               nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0618      0.015      4.115      0.000       0.032       0.091\n",
      "x1             0.0050      0.015      0.334      0.739      -0.025       0.035\n",
      "==============================================================================\n",
      "Omnibus:                      215.488   Durbin-Watson:                   1.861\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1935.812\n",
      "Skew:                           3.638   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.244   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Malaria treatment:\n",
      "                                   OLS Regression Results                                  \n",
      "===========================================================================================\n",
      "Dep. Variable:     events_column_Malaria treatment   R-squared:                       0.002\n",
      "Model:                                         OLS   Adj. R-squared:                 -0.002\n",
      "Method:                              Least Squares   F-statistic:                    0.5342\n",
      "Date:                             Fri, 26 Apr 2024   Prob (F-statistic):              0.466\n",
      "Time:                                     10:44:20   Log-Likelihood:                 174.86\n",
      "No. Observations:                              259   AIC:                            -345.7\n",
      "Df Residuals:                                  257   BIC:                            -338.6\n",
      "Df Model:                                        1                                         \n",
      "Covariance Type:                         nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0154      0.008      2.010      0.045       0.000       0.031\n",
      "x1            -0.0056      0.008     -0.731      0.466      -0.021       0.010\n",
      "==============================================================================\n",
      "Omnibus:                      396.905   Durbin-Watson:                   2.023\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            40862.467\n",
      "Skew:                           7.834   Prob(JB):                         0.00\n",
      "Kurtosis:                      62.506   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Respiratory:\n",
      "                                OLS Regression Results                               \n",
      "=====================================================================================\n",
      "Dep. Variable:     events_column_Respiratory   R-squared:                       0.001\n",
      "Model:                                   OLS   Adj. R-squared:                 -0.002\n",
      "Method:                        Least Squares   F-statistic:                    0.3589\n",
      "Date:                       Fri, 26 Apr 2024   Prob (F-statistic):              0.550\n",
      "Time:                               10:44:20   Log-Likelihood:                 352.79\n",
      "No. Observations:                        259   AIC:                            -701.6\n",
      "Df Residuals:                            257   BIC:                            -694.5\n",
      "Df Model:                                  1                                         \n",
      "Covariance Type:                   nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0039      0.004      0.999      0.319      -0.004       0.011\n",
      "x1            -0.0023      0.004     -0.599      0.550      -0.010       0.005\n",
      "==============================================================================\n",
      "Omnibus:                      587.761   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           703339.050\n",
      "Skew:                          15.966   Prob(JB):                         0.00\n",
      "Kurtosis:                     256.288   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Respiratory Support:\n",
      "                                    OLS Regression Results                                   \n",
      "=============================================================================================\n",
      "Dep. Variable:     events_column_Respiratory Support   R-squared:                       0.011\n",
      "Model:                                           OLS   Adj. R-squared:                  0.008\n",
      "Method:                                Least Squares   F-statistic:                     2.977\n",
      "Date:                               Fri, 26 Apr 2024   Prob (F-statistic):             0.0857\n",
      "Time:                                       10:44:20   Log-Likelihood:                 60.510\n",
      "No. Observations:                                259   AIC:                            -117.0\n",
      "Df Residuals:                                    257   BIC:                            -109.9\n",
      "Df Model:                                          1                                         \n",
      "Covariance Type:                           nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0386      0.012      3.231      0.001       0.015       0.062\n",
      "x1             0.0206      0.012      1.725      0.086      -0.003       0.044\n",
      "==============================================================================\n",
      "Omnibus:                      273.746   Durbin-Watson:                   2.115\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5473.260\n",
      "Skew:                           4.706   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.460   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Respiratory support:\n",
      "                                    OLS Regression Results                                   \n",
      "=============================================================================================\n",
      "Dep. Variable:     events_column_Respiratory support   R-squared:                       0.000\n",
      "Model:                                           OLS   Adj. R-squared:                 -0.004\n",
      "Method:                                Least Squares   F-statistic:                   0.01268\n",
      "Date:                               Fri, 26 Apr 2024   Prob (F-statistic):              0.910\n",
      "Time:                                       10:44:20   Log-Likelihood:                -132.39\n",
      "No. Observations:                                259   AIC:                             268.8\n",
      "Df Residuals:                                    257   BIC:                             275.9\n",
      "Df Model:                                          1                                         \n",
      "Covariance Type:                           nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2046      0.025      8.132      0.000       0.155       0.254\n",
      "x1             0.0028      0.025      0.113      0.910      -0.047       0.052\n",
      "==============================================================================\n",
      "Omnibus:                       57.184   Durbin-Watson:                   1.944\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               92.761\n",
      "Skew:                           1.464   Prob(JB):                     7.20e-21\n",
      "Kurtosis:                       3.144   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Respiratory support+D14:E39:\n",
      "                                        OLS Regression Results                                       \n",
      "=====================================================================================================\n",
      "Dep. Variable:     events_column_Respiratory support+D14:E39   R-squared:                       0.008\n",
      "Model:                                                   OLS   Adj. R-squared:                  0.004\n",
      "Method:                                        Least Squares   F-statistic:                     2.036\n",
      "Date:                                       Fri, 26 Apr 2024   Prob (F-statistic):              0.155\n",
      "Time:                                               10:44:20   Log-Likelihood:                 353.63\n",
      "No. Observations:                                        259   AIC:                            -703.3\n",
      "Df Residuals:                                            257   BIC:                            -696.1\n",
      "Df Model:                                                  1                                         \n",
      "Covariance Type:                                   nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0039      0.004      1.002      0.317      -0.004       0.011\n",
      "x1            -0.0055      0.004     -1.427      0.155      -0.013       0.002\n",
      "==============================================================================\n",
      "Omnibus:                      585.140   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           685160.434\n",
      "Skew:                          15.811   Prob(JB):                         0.00\n",
      "Kurtosis:                     252.980   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Sepsis:\n",
      "                             OLS Regression Results                             \n",
      "================================================================================\n",
      "Dep. Variable:     events_column_Sepsis   R-squared:                       0.000\n",
      "Model:                              OLS   Adj. R-squared:                 -0.004\n",
      "Method:                   Least Squares   F-statistic:                  0.006190\n",
      "Date:                  Fri, 26 Apr 2024   Prob (F-statistic):              0.937\n",
      "Time:                          10:44:20   Log-Likelihood:                -89.509\n",
      "No. Observations:                   259   AIC:                             183.0\n",
      "Df Residuals:                       257   BIC:                             190.1\n",
      "Df Model:                             1                                         \n",
      "Covariance Type:              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1351      0.021      6.337      0.000       0.093       0.177\n",
      "x1             0.0017      0.021      0.079      0.937      -0.040       0.044\n",
      "==============================================================================\n",
      "Omnibus:                      109.879   Durbin-Watson:                   2.181\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              267.174\n",
      "Skew:                           2.134   Prob(JB):                     9.64e-59\n",
      "Kurtosis:                       5.556   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_Transfusion of blood:\n",
      "                                    OLS Regression Results                                    \n",
      "==============================================================================================\n",
      "Dep. Variable:     events_column_Transfusion of blood   R-squared:                       0.000\n",
      "Model:                                            OLS   Adj. R-squared:                 -0.004\n",
      "Method:                                 Least Squares   F-statistic:                   0.07459\n",
      "Date:                                Fri, 26 Apr 2024   Prob (F-statistic):              0.785\n",
      "Time:                                        10:44:20   Log-Likelihood:                 211.38\n",
      "No. Observations:                                 259   AIC:                            -418.8\n",
      "Df Residuals:                                     257   BIC:                            -411.6\n",
      "Df Model:                                           1                                         \n",
      "Covariance Type:                            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0116      0.007      1.736      0.084      -0.002       0.025\n",
      "x1             0.0018      0.007      0.273      0.785      -0.011       0.015\n",
      "==============================================================================\n",
      "Omnibus:                      435.989   Durbin-Watson:                   2.019\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            74920.675\n",
      "Skew:                           9.125   Prob(JB):                         0.00\n",
      "Kurtosis:                      84.298   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_bronchodilator support:\n",
      "                                     OLS Regression Results                                     \n",
      "================================================================================================\n",
      "Dep. Variable:     events_column_bronchodilator support   R-squared:                       0.000\n",
      "Model:                                              OLS   Adj. R-squared:                 -0.003\n",
      "Method:                                   Least Squares   F-statistic:                    0.1194\n",
      "Date:                                  Fri, 26 Apr 2024   Prob (F-statistic):              0.730\n",
      "Time:                                          10:44:20   Log-Likelihood:                 146.27\n",
      "No. Observations:                                   259   AIC:                            -288.5\n",
      "Df Residuals:                                       257   BIC:                            -281.4\n",
      "Df Model:                                             1                                         \n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0193      0.009      2.250      0.025       0.002       0.036\n",
      "x1            -0.0030      0.009     -0.346      0.730      -0.020       0.014\n",
      "==============================================================================\n",
      "Omnibus:                      367.954   Durbin-Watson:                   2.038\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            25714.390\n",
      "Skew:                           6.982   Prob(JB):                         0.00\n",
      "Kurtosis:                      49.774   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_death:\n",
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     events_column_death   R-squared:                         nan\n",
      "Model:                             OLS   Adj. R-squared:                    nan\n",
      "Method:                  Least Squares   F-statistic:                       nan\n",
      "Date:                 Fri, 26 Apr 2024   Prob (F-statistic):                nan\n",
      "Time:                         10:44:20   Log-Likelihood:                    inf\n",
      "No. Observations:                  259   AIC:                              -inf\n",
      "Df Residuals:                      257   BIC:                              -inf\n",
      "Df Model:                            1                                         \n",
      "Covariance Type:             nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const               0          0        nan        nan           0           0\n",
      "x1                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
      "Skew:                             nan   Prob(JB):                          nan\n",
      "Kurtosis:                         nan   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Summary for events_column_surgical procedure:\n",
      "                                   OLS Regression Results                                   \n",
      "============================================================================================\n",
      "Dep. Variable:     events_column_surgical procedure   R-squared:                       0.001\n",
      "Model:                                          OLS   Adj. R-squared:                 -0.003\n",
      "Method:                               Least Squares   F-statistic:                    0.1585\n",
      "Date:                              Fri, 26 Apr 2024   Prob (F-statistic):              0.691\n",
      "Time:                                      10:44:20   Log-Likelihood:                 352.68\n",
      "No. Observations:                               259   AIC:                            -701.4\n",
      "Df Residuals:                                   257   BIC:                            -694.3\n",
      "Df Model:                                         1                                         \n",
      "Covariance Type:                          nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0039      0.004      0.998      0.319      -0.004       0.011\n",
      "x1            -0.0015      0.004     -0.398      0.691      -0.009       0.006\n",
      "==============================================================================\n",
      "Omnibus:                      588.076   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           705551.009\n",
      "Skew:                          15.985   Prob(JB):                         0.00\n",
      "Kurtosis:                     256.687   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1871: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return self.mse_model/self.mse_resid\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:957: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\stats\\stattools.py:50: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "filtered_data.dropna(inplace=True)\n",
    "# Prepare the data for regression analysis\n",
    "X = filtered_data[['value']]  # Features\n",
    "y = filtered_data['Events_Column']  # Target variable\n",
    "\n",
    "# One-hot encode the categorical target variable\n",
    "y_encoded = pd.get_dummies(y, prefix='events_column')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit separate regression models for each column in y_encoded\n",
    "models = {}\n",
    "for col in y_encoded.columns:\n",
    "    regression_model = sm.OLS(y_train[col], sm.add_constant(X_train_scaled))\n",
    "    results = regression_model.fit()\n",
    "    models[col] = results\n",
    "\n",
    "# Print summary of regression results for each column\n",
    "for col, model in models.items():\n",
    "    print(f\"Summary for {col}:\")\n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9856\\764660137.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9856\\764660137.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['end_time'] = pd.to_datetime(filtered_data['end_time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patient_id          event_time               event_name  one_hour_count  \\\n",
      "0     B-N-0001 2022-08-09 01:43:00      Respiratory support               2   \n",
      "1     B-N-0001 2022-08-09 01:43:00      Respiratory support               2   \n",
      "2     B-N-0003 2022-09-28 01:43:00        Blood transfusion             158   \n",
      "3     B-N-0003 2022-09-28 05:50:00      Respiratory support             121   \n",
      "4     B-N-0003 2022-09-29 10:31:00      Respiratory support             140   \n",
      "..         ...                 ...                      ...             ...   \n",
      "321   Z-H-0383 2023-06-28 09:59:00                   Sepsis             135   \n",
      "322   Z-H-0384 2023-06-30 02:10:00        Blood transfusion             192   \n",
      "323   Z-H-0385 2023-06-29 07:00:00  Intravenous fluid bolus              54   \n",
      "324   Z-H-0386 2023-06-29 09:54:00        Blood transfusion             118   \n",
      "325   Z-H-0387 2023-06-29 09:53:00               Convulsion             114   \n",
      "\n",
      "     two_hour_count  three_hour_count          duration_bin  \n",
      "0                 2                 2            60 seconds  \n",
      "1                 2                 2            60 seconds  \n",
      "2               313               457            15 seconds  \n",
      "3               223               381            15 seconds  \n",
      "4               356               499  More than 60 seconds  \n",
      "..              ...               ...                   ...  \n",
      "321             240               354            30 seconds  \n",
      "322             423               747            15 seconds  \n",
      "323             134               216  More than 60 seconds  \n",
      "324             234               384  More than 60 seconds  \n",
      "325             230               379            30 seconds  \n",
      "\n",
      "[326 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Convert start_time and end_time to datetime\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "filtered_data['end_time'] = pd.to_datetime(filtered_data['end_time'])\n",
    "\n",
    "# Define a function to count occurrences within a time range\n",
    "def count_occurrences_within_time_range(data, event_time, time_range_hours):\n",
    "    start_range = event_time - timedelta(hours=time_range_hours)\n",
    "    end_range = event_time\n",
    "    count = data[(data['start_time'] >= start_range) & (data['start_time'] <= end_range)]['value'].count()\n",
    "    return count\n",
    "\n",
    "# Define function to assign duration bins\n",
    "def assign_duration_bins(duration):\n",
    "    if duration <= 15:\n",
    "        return '15 seconds'\n",
    "    elif duration <= 30:\n",
    "        return '30 seconds'\n",
    "    elif duration <= 60:\n",
    "        return '60 seconds'\n",
    "    else:\n",
    "        return 'More than 60 seconds'\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through each row\n",
    "for index, row in filtered_data.iterrows():\n",
    "    # Check if there's an event in the Events_Column\n",
    "    if pd.notnull(row['Events_Column']):\n",
    "        event_time = row['start_time']\n",
    "        event_name = row['Events_Column']  # Get the event name\n",
    "        # Count occurrences within 1, 2, and 3-hour intervals\n",
    "        one_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 1)\n",
    "        two_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 2)\n",
    "        three_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 3)\n",
    "        # Assign duration bins\n",
    "        duration_bin = assign_duration_bins(row['duration'])\n",
    "        # Append results to the list\n",
    "        results.append({'patient_id': row['patient_id'], 'event_time': event_time,\n",
    "                        'event_name': event_name,  # Include event name\n",
    "                        'one_hour_count': one_hour_count, 'two_hour_count': two_hour_count,\n",
    "                        'three_hour_count': three_hour_count, 'duration_bin': duration_bin})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Output the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('durationresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9856\\394946281.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'], format='%M:%S.%f')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9856\\394946281.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['end_time'] = pd.to_datetime(filtered_data['end_time'], format='%M:%S.%f')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert 'start_time' and 'end_time' to datetime objects\n",
    "filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'], format='%M:%S.%f')\n",
    "filtered_data['end_time'] = pd.to_datetime(filtered_data['end_time'], format='%M:%S.%f')\n",
    "\n",
    "# Define timedelta for each time window\n",
    "one_hour = pd.Timedelta(hours=1)\n",
    "two_hours = pd.Timedelta(hours=2)\n",
    "three_hours = pd.Timedelta(hours=3)\n",
    "four_hours = pd.Timedelta(hours=4)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "events = []\n",
    "counts_1h = []\n",
    "counts_2h = []\n",
    "counts_3h = []\n",
    "counts_4h = []\n",
    "\n",
    "# Iterate over each event occurrence\n",
    "for index, event_row in filtered_data.iterrows():\n",
    "    event_name = event_row['Events_Column']\n",
    "    event_time = event_row['start_time']\n",
    "    \n",
    "    # Define start times for each time window\n",
    "    start_time_1h = event_time - one_hour\n",
    "    start_time_2h = event_time - two_hours\n",
    "    start_time_3h = event_time - three_hours\n",
    "    start_time_4h = event_time - four_hours\n",
    "    \n",
    "    # Extract data within each time window\n",
    "    data_1h = filtered_data[(filtered_data['start_time'] >= start_time_1h) & (filtered_data['start_time'] <= event_time)]\n",
    "    data_2h = filtered_data[(filtered_data['start_time'] >= start_time_2h) & (filtered_data['start_time'] <= event_time)]\n",
    "    data_3h = filtered_data[(filtered_data['start_time'] >= start_time_3h) & (filtered_data['start_time'] <= event_time)]\n",
    "    data_4h = filtered_data[(filtered_data['start_time'] >= start_time_4h) & (filtered_data['start_time'] <= event_time)]\n",
    "    \n",
    "    # Check if there is a variable in the 'events_column' for the current event\n",
    "    if pd.notna(event_name):\n",
    "        # Count the number of variables in the 'value' column within each time window\n",
    "        count_1h = data_1h['value'].count()\n",
    "        count_2h = data_2h['value'].count()\n",
    "        count_3h = data_3h['value'].count()\n",
    "        count_4h = data_4h['value'].count()\n",
    "        \n",
    "        \n",
    "        # Append the results to the lists\n",
    "        events.append(event_name)\n",
    "        counts_1h.append(count_1h)\n",
    "        counts_2h.append(count_2h)\n",
    "        counts_3h.append(count_3h)\n",
    "        counts_4h.append(count_4h)\n",
    "       \n",
    "# Create a DataFrame from the lists of results\n",
    "results_df = pd.DataFrame({'event': events,\n",
    "                           '1_hour_before': counts_1h,\n",
    "                           '2_hours_before': counts_2h,\n",
    "                           '3_hours_before': counts_3h,\n",
    "                           '4_hours_before': counts_4h\n",
    "                           })\n",
    "\n",
    "# Now, results_df contains the counts of variables in the 'value' column within each specified time window before each event in the 'events_column',\n",
    "# categorized by duration bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import timedelta\n",
    "\n",
    "# # Convert start_time and end_time to datetime\n",
    "# filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "# filtered_data['end_time'] = pd.to_datetime(filtered_data['end_time'])\n",
    "\n",
    "# # Define a function to count occurrences within a time range\n",
    "# def count_occurrences_within_time_range(data, event_time, time_range_hours):\n",
    "#     start_range = event_time\n",
    "#     end_range = event_time + timedelta(hours=time_range_hours)\n",
    "#     count = data[(data['start_time'] > start_range) & (data['start_time'] <= end_range)]['value'].count()\n",
    "#     return count\n",
    "\n",
    "# # Initialize lists to store results\n",
    "# results = []\n",
    "\n",
    "# # Iterate through each row\n",
    "# for index, row in filtered_data.iterrows():\n",
    "#     # Check if there's an event in the Events_Column\n",
    "#     if pd.notnull(row['Events_Column']):\n",
    "#         event_time = row['start_time']\n",
    "#         event_name = row['Events_Column']  # Get the event name\n",
    "#         # Count occurrences within 1, 2, and 3-hour intervals after the event\n",
    "#         one_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 1)\n",
    "#         two_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 2)\n",
    "#         three_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 3)\n",
    "#         # Append results to the list, including event_name\n",
    "#         results.append({'patient_id': row['patient_id'], 'event_time': event_time,\n",
    "#                         'event_name': event_name,  # Include event name\n",
    "#                         'one_hour_count': one_hour_count, 'two_hour_count': two_hour_count,\n",
    "#                         'three_hour_count': three_hour_count})\n",
    "\n",
    "# # Convert results to a DataFrame\n",
    "# results_df2 = pd.DataFrame(results)\n",
    "\n",
    "# # Output the results\n",
    "# print(results_df2)\n",
    "# results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df2.to_excel('results2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import timedelta\n",
    "\n",
    "# # Convert start_time and end_time to datetime\n",
    "# filtered_data['start_time'] = pd.to_datetime(filtered_data['start_time'])\n",
    "# filtered_data['end_time'] = pd.to_datetime(filtered_data['end_time'])\n",
    "\n",
    "# # Define a function to count occurrences within a time range\n",
    "# def count_occurrences_within_time_range(data, event_time, time_range_hours):\n",
    "#     start_range = event_time - timedelta(hours=time_range_hours)\n",
    "#     end_range = event_time\n",
    "#     count = data[(data['start_time'] >= start_range) & (data['start_time'] <= end_range)]['value'].count()\n",
    "#     return count\n",
    "\n",
    "# # Initialize lists to store results\n",
    "# results = []\n",
    "\n",
    "# # Iterate through each row\n",
    "# for index, row in filtered_data.iterrows():\n",
    "#     # Check if there's an event in the Events_Column\n",
    "#     if pd.notnull(row['Events_Column']):\n",
    "#         event_time = row['start_time']\n",
    "#         event_name = row['Events_Column']  # Get the event name\n",
    "#         # Count occurrences within 1, 2, and 3-hour intervals\n",
    "#         one_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 1)\n",
    "#         two_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 2)\n",
    "#         three_hour_count = count_occurrences_within_time_range(filtered_data, event_time, 3)\n",
    "#         # Append results to the list\n",
    "#         results.append({'patient_id': row['patient_id'], 'event_time': event_time,\n",
    "#                         'event_name': event_name,  # Include event name\n",
    "#                         'one_hour_count': one_hour_count, 'two_hour_count': two_hour_count,\n",
    "#                         'three_hour_count': three_hour_count})\n",
    "\n",
    "# # Convert results to a DataFrame\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Output the results\n",
    "# print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results DataFrame to an Excel file\n",
    "# results_df.to_excel('results.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
